{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_MH_model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "v-UNdK-yCTLB"
      ],
      "authorship_tag": "ABX9TyM1hvpmMG1Sc4RfLr2XM3bo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gail529/Mental-health/blob/main/lstm_MH_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54bvoPIZgTGY",
        "outputId": "bf1ef89e-6554-4858-c9fe-82a36f465641"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import gensim\n",
        "import os\n",
        "import tweepy as tw\n",
        " \n",
        "#tweet preprocessing \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import string\n",
        "import re\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize,TweetTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        " \n",
        " \n",
        " \n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        " \n",
        "\n",
        "import pickle \n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,LSTM,GRU\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.initializers import Constant\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, LSTM, Dropout, Activation, Embedding, Bidirectional"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW8CXhEhBaWl"
      },
      "source": [
        "data=pd.read_csv('/content/Mental_health2.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SrqEWYCf2SE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "30737c07-8e77-49d6-cbba-3e3228bdedf9"
      },
      "source": [
        "data.head(2)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweets</th>\n",
              "      <th>Positive</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Anger</th>\n",
              "      <th>Anticipation</th>\n",
              "      <th>Disgust</th>\n",
              "      <th>Fear</th>\n",
              "      <th>Joy</th>\n",
              "      <th>Sadness</th>\n",
              "      <th>Surprise</th>\n",
              "      <th>Trust</th>\n",
              "      <th>afinn_score</th>\n",
              "      <th>positive_vader</th>\n",
              "      <th>negative_vader</th>\n",
              "      <th>neutral_vader</th>\n",
              "      <th>depression_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>i love my family  i love my life  happiness</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333</td>\n",
              "      <td>21.3395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>homosexual will not inherit the kingdom of go...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.104</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.896</td>\n",
              "      <td>25.7540</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... depression_score\n",
              "0           0  ...          21.3395\n",
              "1           1  ...          25.7540\n",
              "\n",
              "[2 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTFtM_4wT1vi"
      },
      "source": [
        "#lowercasing and url,punctuations and numbers removal,\n",
        "def Lowercasing(words):\n",
        "    string=re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\",str(words))\n",
        "    word=string.lower()\n",
        "    return word\n",
        "\n",
        "#Tokenization and (@)handle extraction\n",
        "def Tokenization(tweet):\n",
        "    tokenizer=TweetTokenizer(strip_handles=True)\n",
        "    tokens = tokenizer.tokenize(tweet)\n",
        "    return tokens\n",
        "\n",
        "#punctuations\n",
        "def Punctuation_removal(tokens):\n",
        "    words=[ word for word in tokens if word.isalnum()]\n",
        "    return words\n",
        "\n",
        "#stemming\n",
        "def stemming(text):\n",
        "    stemmer=PorterStemmer()\n",
        "    for  word in text:\n",
        "        stemmed_words=stemmer.stem(word)\n",
        "        return stemmed_words\n",
        "\n",
        "#stopword_removal\n",
        "def remove_stopwords(words):\n",
        "    stop_words=set(stopwords.words(\"english\")) \n",
        "    result=[word for word in words if word not in stop_words ]\n",
        "    return result\n",
        "\n",
        "\n",
        "#lemmatization\n",
        "def lemmatization(text):\n",
        "    lemmatizer=WordNetLemmatizer()\n",
        "    lemmatized_phrase=[]\n",
        "    for word in text:\n",
        "        lemmatized_word=lemmatizer.lemmatize(word)\n",
        "        lemmatized_phrase.append(lemmatized_word)\n",
        "    return lemmatized_phrase\n",
        " "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhIHXQmbzZF4"
      },
      "source": [
        "#code for cleaning a simple tweet\n",
        "def clean_tweet(tweet):\n",
        "    tweet_tokens=Tokenization(tweet)\n",
        "    lemmatized_tweet=lemmatization(tweet_tokens)#lemmatization\n",
        "    lowercased_string=Lowercasing(lemmatized_tweet)#lowercasing and removing numbers\n",
        "    return lowercased_string\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xeOh9nt2VeM"
      },
      "source": [
        "Tokenizing the tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMP7clmMgm6t",
        "outputId": "f2020326-a8d3-4299-c278-02a1044089fe"
      },
      "source": [
        "tweets=data['tweets'].values.tolist()\n",
        "len(tweets)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1904"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOc3IFfojdT8"
      },
      "source": [
        "tweet_list=[]\n",
        "for tweet in tweets:\n",
        "    tokens =  word_tokenize(tweet)\n",
        "    #stop_words=set(stopwords.words(\"english\")) \n",
        "    #word=[word for word in tokens if word not in stop_words]\n",
        "    tweet_list.append(tokens)\n",
        "\n",
        "    "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xs9p4Xe2g1m"
      },
      "source": [
        "Training the word2vec Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B24DKlqYgpp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300ed5f9-f7bc-4726-9d6c-9c3e61071701"
      },
      "source": [
        "EMBEDDING_DIM=100\n",
        "model = gensim.models.Word2Vec(sentences=tweet_list,size=EMBEDDING_DIM,window=5,workers=4,min_count=1)\n",
        "words = list(model.wv.vocab)\n",
        "print('Vocabulary size: %d',len(words))\n",
        "print(words)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: %d 4381\n",
            "['i', 'love', 'my', 'family', 'life', 'happiness', 'homosexual', 'will', 'not', 'inherit', 'the', 'kingdom', 'of', 'god', 'right', 'so', 'guess', 'your', 'homphobic', 'mom', 'we', 'r', 'here', 'to', 'shower', 'our', 'unconditional', 'n', 'alwys', 'felt', 'they', 'both', 'a', 'wanted', 'you', 'are', 'and', 'always', 'be', 'for', 'ever', 'bts', 'praying', 'almighty', 'with', 'good', 'health', 'bountiful', 'patience', 'positivity', 'peace', 'fa', 'worked', 'hard', 'improve', 'on', 'or', 'correct', 'entirely', 'promote', 'self', 'value', 'integrity', 'work', 'persi', 'true', 'me', 'make', 'it', 'happen', 'heart', 'get', 'into', 'place', 'done', 'in', 'future', 'want', 'queen', 'who', 'isn', 't', 'trying', 'live', 'her', 'others', 'market', 'herself', 'like', 'she', 's', 'single', 'time', 'back', 'again', 'together', 'celebrate', 'while', 'serve', 'thing', 'know', 'where', 'do', 'believe', 'eye', 'especially', 'when', 'entertaining', 'those', 'take', 'care', 'truly', 'feel', 'happin', 'wish', 'hope', 'everlasting', 'joy', 'thank', 'being', 'best', 'friend', 'may', 'b', '1111', 'loved', 'confidence', 'motivation', 'money', 'equality', 'able', 'no', 'the5in5', 'tomorrow', 'have', 'been', 'feeling', 'little', 'under', 'weather', 'today', 'getting', 'some', 'rest', 'thanks', 'advance', 'f', 'remove', 'three', '2friends', 'school', 'mate', 'step', 'up', 'girldad', 'stepping', 'prek', '4', 'morning', 'maggie', 'wishing', 'all', 'wonderful', 'day', 'chilly', 'cooler', 'then', 'he', 'what', 'is', 'most', 'important', 'defines', 'quality', 'humans', 'career', 'sha', 'by', 'engaging', 'activity', 'from', 'these', '3', 'categoriesor', 'combine', 'category', 'youll', 'l', 'never', 'let', 'anyone', 'come', 'between', 'bag', 'respect', 'dignity', 'education', 'overall', 're', 'an', 'adult', 'can', 'choose', 'whoever', 'help', 'att', 'am', 'sorry', 'this', 'happened', 'but', 'happy', 'cut', 'toxic', 'member', 'off', 'living', 'inks', 'ha', 'far', 'grateful', 'part', 'many', 'month', 'year', 'cooking', 'fun', 'u', 'share', 'gluten', 'free', 'recipe', 'too', 'celi', 'ppl', 'ada', 'now', 'first', 'shes', 'chasing', 'man', 'own', 'bc', 'belief', 'shed', 'openminded', 'people', 'think', 'that', 'way', 'don', 'their', 'grandkid', 'funny', 'how', 'hide', 'identity', 'blurt', 'out', 'hateful', 'message', 'well', 'atleast', 'valentine', 'c', 'dont', 'situation', 'popped', 'feed', 'just', 'wan', 'na', 'say', 'youre', 'beauti', 'val', 'scott', 'found', 'at', 'sight', 'his', 'meddling', 'them', 'keep', 'happines', 'shane', 'wa', 'noisy', 'heir', 'before', 'sport', 'referee', 'came', 'surprising', 'tale', 'about', 'perfect', 'allan', 'tish', 'over', 'moon', 'engagement', 'next', 'chapter', 'fi', 'bos', 'passionate', 'teacher', 'treated', 'extension', 'very', 'large', 'happiest', 'birthday', 'nanay', 'josefina', 'cuevaspanganiban', 'really', 'having', '2', 'skittles', 'awwwwww', 'pawsome', 'furrends', 'send', 'lot', 'purrs', 'praye', '9', 'close', 'second', 'pet', 'im', 'point', 'frie', 'remember', 'were', 'excited', 'go', 'fast', 'yesterday', 'h', 'stolitz', 'much', 'unwarranted', 'hated', 'stolas', 'should', 'leave', 'marriage', 'form', 'healthy', 'another', 'fake', 'account', 'dedicated', 'ruin', 'yet', 'claim', 'ob', 'home', 'alone', 'cry', 'tear', 'after', 'kind', 'word', 'gift', 'card', 'hug', 'company', 'made', 'even', 'gone', 'success', 'there', 'which', 'exceedingly', 'boring', 'describe', 'appreciate', 'amazing', 'twitter', 'wholesome', 'v', 'one', 'hold', 'chris', 'regular', 'scottish', 'until', 'cleaner', 'suggest', 'if', 'classless', 'society', 'as', 'figure', 'm', 'blessed', 'humility', 'weal', 'bhai', 'give', 'ur', 'bcs', 'li', '8th', 'sweet', 'abigail', 'brings', 'nice', 'hear', 'great', 'safe', 'greece', 'full', 'laughter', 'tho', 'equate', 'see', 'nigga', 'treat', 'gave', 'freedom', 'someone', 'knew', 'w', 'bless', 'him', 'thier', 'mental', 'rashamians', 'dailydevotions', 'through', 'christ', 'june', '22', 'joyfully', 'wife', 'whom', 'thou', 'lovest', 'al', 'wrenching', 'story', 'thread', 'reiterate', 'worthy', 'proud', 'brian', 'trust', 'ge', 'sum', '1', 'rubbish', 'hate', 'bigger', 'thn', 'grandchildrens', 'support', 'such', 'witch', 'boy', 'girl', 'sirius', 'bus', 'find', 'furever', 'loving', 'crazy', 'pentecostal', 'religious', 'nor', 'desire', 'inflict', 'view', 'move', 'learn', 'interesting', 'chile', 'nature', 'hometown', 'smile', 'laugh', 'because', 'extreme', 'plan', 'fuck', 'em', 'tough', 'cutting', 'something', 'need', 'ahem', 'happiosity', 'natal', 'glad', 'alhamdullilah', 'every', 'wake', 'financial', 'stability', 'cruel', 'world', 'ready', 'queer', 'person', 'yourself', 'page', 'left', 'question', 'mostly', '1051', 'anne', 'does', 'mean', 'communicate', 'beca', 'delete', 'permanently', '5', '6', 'rays', 'player', 'molded', 'encouraged', 'themselves', 'doing', 'dear', 'bruce', 'surrounded', 'middle', 'desert', 'nnnnnn', 'instagood', 'pick', 'gathering', 'reunion', 'might', 'coming', 'soon', 'spending', 'more', 'incredibly', 'sad', 'bring', 'daughter', 'would', 'actual', 'hour', 'mine', 'shove', '10', 'ac', 'cost', 'workweeks', 'boost', 'matter', 'enjoy', 'granted', 'continue', 'silline', 'strongly', 'disagree', 'sidneys', 'choice', 'cold', 'put', 'hap', 'thought', 'going', 'diversity', 'nasty', 'continent', 'medi', 'birthdays', 'happ', 'financially', 'stable', 'won', 'continued', 'growth', 'mon', 'united', 'strong', 'disheartened', 'only', 'sister', 'filled', 'joyful', 'vibration', 'forever', 'indebted', 'beautiful', 'sending', 'lots', 'ashaangi', 'honesty', 'faithfulness', 'romantic', 'romance', 'fanfam', 'sorrow', 'eachother', 'wonder', 'y', 'emotional', 'rn', 'fam', 'lets', 'spread', 'cra', 'hoping', 'bestie', 'visiting', 'homeland', 'minimal', 'stress', 'maximum', 'kid', 'deserves', 'everything', 'positive', 'u0001f90d', 'sg', 'dil', 'ki', 'dhadkan', 'devyaan', 'earth', 'exactly', 'already', 'taken', 'sunshine', 'edinburgh', 'scotland', 'u000e0067', 'u000e0062', 'u000e0073', 'u000e0063', 'u000e0074', 'u000e007f', 'sir', 'gm', 'allison', 'spiritual', 'jesus', 'reign', 'supreme', 'different', 'domestic', 'soft', 'deserve', 've', 'had', 'winning', 'moment', 'attain', 'level', 'achieving', 'th', 'mirror', 'bad', 'worst', 'khushishah', 'khushi', 'fashion', 'style', 'thalapathy', 'vijay', 'inspired', 'cheered', 'directed', 'heres', 'bright', 'early', 'everyone', 'meaning', 'existence', 'happinesswe', 'solution', 'heading', 'baby', 'sendi', 'truck', 'drivers', 'detroit', 'same', 'meet', 'swastikashines', 'announce', '200', '000', 'clientele', 'expa', 'crumbling', 'down', 'tell', 'exp', 'japanese', 'turkish', 'friendship', 'throughout', 'history', 'congrats', 'blake', 'gwen', 'rarely', 'talked', 'said', 'each', 'other', 'friends', 'lo', 'week', 'turn', 'fabulous', 'architect', 'nicola', 'varkevisser', 'congratulations', 'oneye', 'guy', 'big', 'bond', 'asian', 'totally', 'relate', 'stacking', 'bread', 'taking', 'keeping', 'myself', 'unlocked', 'new', 'nothing', 'count', 'age', 'john', 'lennon', 'ecobud', 'happybirthdaykavin', 'tuesday', 'happytuesday', 'selflove', 'healing', 'positiveenergy', 'quotes', 'two', 'private', 'wanting', 'ms', 'gadot', 'actress', 'demon', 'deserved', 'soul', 'somewhere', 'amaz', 'eugenie', 'theres', 'ton', 'sure', 'also', 'genuinely', 'reciprocated', 'thats', 'why', 'stay', 'long', 'neenga', 'ahh', 'e', 'pill', 'source', 'strength', 'comfort', 'worth', 'yes', 'sideways', 'cause', 'double', 'staying', 'balance', 'key', 'its', 'married', 'couple', 'relationship', 'talk', 'thodu', 'needa', 'etc', 'sugar', 'coated', 'unconventional', 'sacrifice', 'kargil', 'hero', 'nation', 'above', 'father', 'didn', 'honestly', 'idk', 'mad', 'negative', 'towards', 'happi', 'precious', 'parent', 'meditate', 'read', 'book', 'solve', 'problem', 'thy', 'neighbor', 'speak', 'famil', 'thanx', 'fact', 'ancient', 'modern', 'body', 'futuristic', 'request', 'fridaylivestream', 'summer', 'arashi', 'music', 'video', 'played', 'fls', 'onemonth', 'grow', 'enti', 'succes', 'protection', 'blessing', 'tc', 'charmant', 'didi', 'prince', 'pray', 'sm', 'ugh', 'virtual', 'sharing', 'pradeep', 'ji', 'lord', 'hanumanji', 'miss', 'mahi', 'nanakdev', 'madhu', 'dr', 'arohi', 'sunanda', 'goodnight', 'maga', 'patriot', 'bidencheated', 'abortionismurder', 'americaneedsjesus', 'prayforamerica', 'joyous', 'chiandana', '100', 'pandit', 'sapna', 'pe', 'karuna', 'chowdhary', 'sahab', 'upadhyay', 'parul', 'didnt', 'irritate', 'taehyung', 'contrary', 'content', 'happybirthdaythalapathy', 'happiee', 'wisdom', 'doodle', 'nnnn', 'mentalhealthawareness', 'community', 'prosperity', 'camera', 'focused', 'longer', 'than', 'usual', 'ahir', 'revealed', 'shakhi', 'dard', 'picture', 'edited', 'filtered', 'memo', 'children', 'purr', 'louder', 'still', 'once', 'bachelor', 'mayema', 'q', 'da', 'greatest', '1aimat3', '1aim', '1aimmedia', '1aimyouthchurch', 'wizards', 'brooklyn', 'surfer', 'grumpy', 'priceless', 'collection', 'curve', 'set', 'everythin', 'loss', 'toxicity', 'aside', 'vj', 'ai', 'myx', 'welcome', 'somehow', 'force', 'head', 'monday', 'kids', 'photooftheday', 'cute', 'momlife', 'picoftheday', 'mewlions', 'complete', 'princess', 'bringing', 'jeddawis', 'relative', 'makkah', 'eid', 'swear', 'd', 'general', 'infant', 'newborn', 'revived', 'dimension', 'mars', 'alien', 'war', 'regardl', 'eggcellent', 'auntielife', 'hatchingplans', 'dinomite', 'rogerwilliamszoo', 'rhodeisland', 'add', 'appreciated', 'prayer', 'son', 'papam', 'lend', 'helping', 'hand', 'toda', 'saved', 'patch', 'usually', 'start', 'heard', 'song', 'immediately', 'remind', 'br', 'regardless', 'any', 'recent', 'drama', 'look', 'blocking', 'biological', 'som', 'absolutely', 'striving', 'yagi', 'fathers', 'northern', 'manhattan', 'lady', 'struggling', 'driver', 'seoul', 'course', 'old', 'changed', 'mother', 'sibling', 'across', 'kindness', 'becau', 'bri', 'upbeat', 'super', 'fan', 'occasion', 'visit', 'immerse', 'ourselves', 'baba', 'whose', 'manifest', 'doe', 'break', 'gon', 'marry', 'zemo', 'adopting', 'though', 'proper', 'words', 'brilliant', 'child', 'follow', 'minute', 'ish', 'inspirational', 'tutorial', 'glow', '7', 'inspiration', 'demi', 'anna', 'real', 'duaas', 'allah', 'swt', 'experience', 'deser', 'wedding', 'season', 'whi', 'leimert', 'park', 'capturing', 'celebration', 'juneteenth', 'spirit', 'texture', 'flavor', 'oh', 'nnnnnnnnnnnnnnn', 'cider', 'hardcider', 'centralcoast', 'slo', 'summervibes', 'name', 'tag', 'moot', 'travel', 'sea', 'castro', 'trusting', 'team', 'fellow', 'lgbtq', 'past', 'emotionally', 'unattached', 'ease', 'bec', 'futa', 'vitu', 'vitatu', 'kwenye', 'maisha', 'yako', 'afternoon', 'william', '100k', 'beaming', 'reach', 'height', 'built', 'please', 'dog', 'gaza', 'innocent', 'ch', 'rich', 'hmm', 'weird', 'lovely', 'moo', 'songs', 'bridge', 'maybe', 'hopeless', 'offer', 'deepest', 'heartfelt', 'condolence', 'familys', 'senseless', 'vi', 'racism', 'huh', 'idgaf', 'could', 'dad', 'campartner', 'dallas', 'texas', 'dfw', 'fathersday', 'dadday', 'charity', 'woul', 'lotto', 'buy', 'wi', 'shauryaauranohikikahani', 'halfday', 'kelsang', 'khacho', 'understand', 'tantra', 'quickly', 'accomplish', 'amen', 'ahead', 'anniversary', '12', 'years', '1st', 'grew', 'ultimately', 'congratulation', 'appu', '1m', 'insta', 'familymany', 'yo', 'ga', 'murah', 'rezeki', 'selaluuu', 'training', 'tool', 'within', 'plea', 'separation', 'act', 'itself', 'despite', 'possibility', 'seokhyung', 'neikaarapatticurdkurma', 'based', 'expectat', 'easy', 'difficult', 'looking', 'answer', 'chinese', 'thankful', 'womenspodium', 'thankyou', 'gratitude', 'luck', 'ka', 'showered', 'days', 'familylove', '3rd', 'got', 'tagged', 'reason', 'denji', 'cool', 'character', 'literally', 'teen', 'shitty', 'lived', 'lasted', 'weekend', 'pure', 'whole', 'fathersdaygifts', 'happyfathersday', 'fathersday2021', 'fatherson', 'hey', 'trey', 'must', 'awesome', 'huge', 'ape', 'adore', 'highness', 'special', 'shared', 'fri', 'rome', 'pathetic', 'enough', 'camilla', 'social', 'worker', 'turned', 'ups', 'toget', 'hbdthalapathyvijay', 'beyond', 'measure', 'yr', 'sacrificing', 'natural', 'drug', 'date', 'xole', 'irregardless', 'dearest', 'bird', 'flew', 'bogdan', 'check', 'p', 'eople', 'alot', 'period', 'become', 'noah', 'planet', 'leimertpark', 'safety', 'cake', 'cooky', 'cak', 'pyari', 'feri', 'sweetest', 'entertainer', 'interacted', 'le', 'childhood', 'simple', 'things', 'brought', 'us', 'gdafternoon', 'smiling', 'modi', 'poses', 'idea', 'bestfriends', 'gurly', 'girly', 'daddies', 'without', 'end', 'george', 'strait', 'bestow', 'papa', 'wh', 'darlings', 'faith', 'thankfulnees', 'chef', 'gardener', 'dinner', 'party', 'guadalajara', 'dull', 'hip', 'hopper', 'damulag', 'gelatin', 'fit', 'secret', 'lifestay', 'practice', 'yoga', 'safehappy', 'international', 'pain', 'misunderstand', 'ak', 'sk', 'giving', 'cha', 'temporary', 'residence', 'wont', 'attached', 'shivangians', 'extended', 'ours', 'growing', 'stronger', 'whats', 'motivationour', 'nowenjoy', 'show', 'haven', 'energy', 'wrap', 'around', 'making', 'better', '20june2021', 'solstice', '621', '2021', '222', '11', 'powerful', 'portal', 'light', 'infused', 'infinite', 'selfie', 'university', 'dude', 'zerohalliburton', 'zh', 'lifeinpursuit', 'zerocase', 'zhtravelingbag', 'aluminum', 'died', 'grandma', 'kitty', 'ended', 'kill', 'shelter', 'murder', 'senior', 'coperon', 'solid', 'rock', 'human', 'pr', 'papiii', 'teach', 'deal', 'anger', 'effort', 'chen', 'ot9', 'stan', 'gods', 'mighty', 'ayatsuji', 'passion', 'floor', 'sky', 'sun', 'star', 'o', 'ocean', 'nnnnn', 'pacificocean', 'canada', 'vancouver', 'portmoody', 'boss', 'lil', 'wow', 'photo', 'radiates', 'melody', 'sadnes', 'celebrating', 'holiday', 'environment', 'kickoff', 'last', 'high', 'upcoming', 'graduation', 'challenging', 'foolish', 'russ', 'example', 'delicate', 'game', 'impo', 'usain', 'bolt', 'tha', 'bounty', 'beginning', 'blissful', 'neverendings', 'adorable', 'addition', 'gd', 'mrngg', 'power', 'chellamas', 'face', 'digital', 'someday', 'nastasia', 'gurl', 'oncecomesbeforetwice', 'twice', 'happyfathersday2021', 'stresstosuccessformula', 'linkedinfamily', 'hater', 'patty', 'waszak', 'asks', 'musical', 'danced', 'daddy', 'created', 'incredible', 'comfortable', 'exists', 'jeff', 'finally', 'rob', 'fr', 'xicheng', 'entire', 'endless', 'positiv', 'raising', 'u200d', 'knelt', 'eliza', 'frustrated', 'provides', 'atlantic', 'decided', 'raise', 'murdered', 'whately', 'marvin', 'call', 'dedicate', 'sick', 'patien', 'destroy', 'bakers', 'chicago', 'youtuber', 'loud', 'taught', 'empathy', 'smalles', 'news', 'barbara', 'cuddle', 'af', 'kim', 'jongdae', 'judge', 'bricklayer', 'ludicrous', 'featurin', 'michael', 'gorge', 'hunterdcartlidge', 'sydneycartlidge', 'halekulani', 'yours', 'corbett', 'amanda', 'mama', 'lynn', 'room', 'corbetts', 'wid', 'ask', 'anything', 'heal', 'telangana', 'tigeress', 'dynamic', 'energetic', 'visionary', 'leader', 'wallawani', 'top', 'pursuit', 'pay', 'ganna', 'sink', 'supporting', 'atm', 'chosen', 'providing', 'aunty', 'ive', 'receive', 'portrait', 'arbaaz', 'khan', 'paradise', 'shaa', 'j', 'men', 'recogni', 'present', 'handmade', 'art', 'giftideas', 'albert', 'sheriff', 'elton', 'pawsitive', 'santiago', 'black', 'designer', 'flamboyant', 'cornbread', 'table', 'feat', 'douglas', 'haines', 'bob', 'country', 'folk', 'serdar', 'honoring', 'dads', 'victoria', 'okay', 'wala', 'mag', 'papakilig', 'sakin', 'totall', 'shaan', 'sushant', 'donkiss', 'donkissfam', 'donny', 'pangilinan', 'k', 'indeed', 'recreate', 'fantastic', 'rachel', 'painter', 'bartender', 'tur', 'spend', 'build', 'everywhere', 'fans', 'sallu', 'mr', 'president', 'professi', 'replying', 'fo', 'superhero', 'breakfast', 'bed', 'pizza', 'picnic', 'hi', 'amy', 'toge', 'awwww', 'endearingly', 'fatherslove', 'cherishable', 'wouldnt', 'stop', 'started', 'mentioning', 'memory', 'instagram', 'rivera', 'caring', 'naya', 'embodiment', 'paralegals', 'jersey', 'stock', 'investor', 'perplexing', 'depression', 'swing', 'emotion', 'completely', 'muted', 'wang', 'lov', 'vilicious', 'daughterlove', 'daddiesgirl', 'di', 'happine', 'kiddos', 'drink', 'admirable', 'fishing', 'heaven', 'upon', 'rely', 'beth', 'postcard', 'certainly', 'unfor', 'fatherhood', 'net', 'wellbeing', 'sacrific', 'beckys', 'learned', 'wait', 'create', 'playing', 'sims', 'everybody', 'household', 'successful', 'followed', 'retweeted', 'tweets', 'ca', 'cant', 'watch', 'episode', 'express', 'sri', 'gracious', 'presence', 'insp', 'cheer', 'hfd', 'cherish', 'nate', 'quiet', 'vietnamese', 'woman', 'secretary', 'exciting', 'role', 'model', 'appreciation', 'canadian', 'serving', 'seniors', 'superheroes', 'champ', 'fur', 'brother', 'presidents', 'carter', 'clinton', 'bush', 'obama', 'biden', 'pop', 'showing', 'lower', 'boundless', 'fianc', 'omelette', 'holding', 'wound', 'kix', '106', 'masterpiece', 'antoi', 'load', 'lifelong', 'fulltime', 'job', 'headache', 'tochi', 'burst', 'fatherlove', 'hears', 'gentle', 'voice', 'lydia', 'behind', 'leroy', 'christen', 'stroller', 'tehidy', 'wood', 'strangely', 'compelled', 'shoot', 'tree', 'along', 'terlalu', 'memaksa', 'diriku', 'menyibukkan', 'bolotin', 'magnificent', 'enjoying', 'gorgeous', 'grandchil', 'naa', 'alla', 'ya', 'irundhadhe', 'indha', 'reached', 'consistent', 'evidence', 'psy', 'enga', 'amma', 'kuda', 'nalla', 'vechi', 'seyuvange', 'adhuku', 'appa', 'vittu', 'irukamudiyadu', 'understanding', 'omg', 'doesn', 'specialday', 'dodger', 'shawn', 'gre', 'sons', 'daughters', 'underestimate', 'importance', 'given', 'duty', 'seriously', 'luckiest', 'purest', '252', 'hello', 'side', 'wondering', 'spe', 'pretty', 'play', 'maple', 'reinders', 'biggest', 'recogn', 'food', 'prashant', 'fav', 'jammwalions', 'votechriscastillo', 'husband', 'co', 'women', 'protect', 'grand', 'rising', 'owoourworldorder', 'coffee', 'goodmorning', 'coffeeshop', 'hanoi', 'michelle', 'upside', 'truth', 'blessings', 'pra', 'pcfcu', 'weekendvibes', 'foodies', 'restaurant', 'hotsummerdays', 'artemis', 'working', 'tirelessly', 'provide', 'whatever', 'inve', 'teton', 'tetonfamily', 'alike', 'cheers', 'blood', 'appreciates', 'admire', 'nn', 'dadsday', 'dadsdayoff', 'tranquility', 'shout', 'sean', 'shah', 'surprise', 'mor', 'cathyerskine', 'teamlogue', 'arriveathome', 'susansterbinsky', 'sonniamartorana', 'foundation', 'nothi', 'everyday', 'laug', 'lost', 'yrs', 'strict', 'thin', 'heavy', 'celebr', 'jack', 'giles', 'durantastic', 'ipromiseyou', 'wherever', 'legacy', 'highschool', 'used', 'theyre', 'stopping', 'universe', 'shepi', 'twitterverse', 'outside', 'thru', 'since', 'facilitator', '07', 'gaudencio', 'selfless', 'contentment', 'tackle', 'difficulties', 'tim', 'desir', 'accept', 'lucky', 'idiot', 'moron', 'lovable', 'known', 'expressed', 'bcz', 'deserv', 'fortieth', 'yemisi', 'seldom', 'breed', 'overdose', 'praise', 'genuine', 'leadership', 'devotion', 'guide', 'companion', 'gr', 'wasn', 'wouldn', 'honour', 'night', 'track', 'razz', 'carers', 'mum', 'specia', 'unconditionally', 'tireless', 'epitome', 'courage', 'affection', 'luminiser', 'ev', 'isnt', 'dancer', 'singer', 'performer', 'artist', 'hardworking', 'hande', 'jimmy', 'parolis', 'harry', 'dimitri', 'needed', 'compiled', 'alive', 'sunday', 'holy', 'bette', 'serf', 'dy', 'abu', 'highest', 'jannah', 'hea', 'small', 'gesture', 'unsung', 'jays', 'jay', 'enha', 'expect', 'return', 'wishi', 'deep', 'thankyu', '127', 'kyummunity', 'slowly', '333', 'reasons', 'leela', 'orchid', 'greens', 'wishes', 'ver', 'awaits', 'anywhere', 'thangachi', 'youuuu', 'yall', 'hav', 'note', 'forget', 'doesnt', 'creator', 'youtube', 'rahul', 'kanaujia', 'believed', 'saw', 'kindhearted', 'humble', 'internationalfathersday', 'daddysday', 'closeknit', 'city', 'fear', 'unseen', 'unexpressed', 'remains', 'pillar', 'stre', 'ordinary', 'adventurer', 'storyteller', 'fathe', 'luv', 'theirs', 'openly', 'dadlife', 'intending', 'doctor', 'idol', 'unfollow', 'lol', 'll', 'stuff', 'medium', 'whether', 'refreshing', 'captures', 'innocence', 'fatherfigure', 'mentor', 'teerth2work', 'coworking', 'teerth', 'teerthrealties', 'struggle', 'project', 'remain', 'acknowledge', 'ensuring', 'erg', 'commemorates', 'took', 'length', 'trans', 'bestdad', 'solitary', 'mountain', 'aspiring', 'zaddy', 'fucking', 'ooooo', 'frame', 'jagannath', 'ye', 'invest', 'perfe', 'seen', 'sacrificed', 'breath', 'sweat', 'comfo', 'aka', 'often', 'pioneer', 'institute', 'box', 'opportunity', 'priority', 'tears', 'fears', 'necessary', 'away', 'till', 'buster', 'stayed', 'times', 'cheering', 'succeed', 'ty', 'doting', 'number', 'newest', 'uncle', 'robby', 'goi', 'fathering', 'angel', 'winworld', 'realty', 'alwa', 'streng', 'neither', 'anchor', 'sail', 'guiding', 'hardships', 'ambition', 'belonging', 'blog', 'death', 'destiny', 'wear', 'cape', 'reallife', 'inpro', 'nnn', 'inprocorpindia', 'standing', 'weak', '26', 'drive', 'wasnt', 'ago', 'astrologermanishakoushik', 'betaji', 'naimu', 'try', 'simplehabits', 'agree', 'motivate', 'path', 'mew', 'suppasit', 'fireworks', '2m', 'onl', 'childs', 'unmatched', 'tonic', 'happyfathers', 'troubleshooter', 'maheshadvertisinganddesign', 'hundred', 'schoolmaster', 'vardhamanhomesmumbai', 'bombsquaddigitalsolutions', 'catch', 'fall', 'instead', 'brush', 'ag', 'stand', 'interior', 'pharmacist', 'cruise', 'los', 'angeles', 'alwaysthere', 'pillarofstrength', 'mylife', 'thelegend', 'goat', 'tym', 'greater', 'jealous', 'commitment', 'surp', 'exquisite', 'cantonese', 'delicacy', 'hearty', 'western', 'decadent', 'pastry', 'moving', 'forward', 'follower', 'tesorosdelverbo', 'boyfriend', 'bday', 'vibe', 'absolute', 'honor', 'bound', 'rip', 'losing', 'hurt', 'apart', 'sometimes', 'beloved', 'maxx', 'boxer', 'mix', 'goal', 'dream', 'aspiration', 'himself', 'fathersday2021s', 'simply', 'bcuz', 'hs', 'suffering', 'reduction', 'breakdown', 'sex', 'watched', 'rebelabc', 'surge', 'win', 'forgiveness', 'went', 'quirky', 'kaitlyn', 'late', 'host', 'met', 'grace', 'au', 'menye', 'aldersgate', '30th', 'belong', 'did', 'buried', 'celebrated', 'confusio', 'nino', 'retail', 'workers', 'outrageous', 'computer', 'programmer', 'protector', 'provider', 'serenity', 'wea', 'luky', '18th', 'older', 'verappl', 'veracity', 'fidelity', 'accuracy', 'wrong', 'fugazi', 'connection', 'actriv', 'ma', 'bible', 'founders', 'constitution', 'law', 'order', 'champmr', 'extending', 'sorro', 'rosie', 'su', 'immense', 'tribe', 'flamemates', '72', 'flame', 'mates', 'praising', 'thanking', 'emanates', 'ari', 'write', 'heroes', 'strive', 'collective', 'uploads', 'abc', 'lowkey', 'devastating', 'rejoice', 'settle', 'harm', 'giacomo', 'imagine', 'canine', 'during', 'fandom', 'beaut', '16yo', 'autistic', 'nonverbal', 'ipad', 'proloquo', 'fame', 'state', 'caesar', 'madly', 'gay', 'influence', 'judges', 'york', 'paleonthologist', 'moist', 'cat', 'pets', 'considered', 'ho', 'bollywoodflashback', 'sitara', 'evening', 'smil', 'danny', 'loose', 'weight', 'eventually', 'broug', 'happybirthdayashubhaiya', 'ashu', 'prosper', 'piece', 'alarm', 'google', '156', 'realized', 'weve', 'group', 'lem', '5things', 'cuppa', 'vid', 'chat', 'garden', 'lif', 'dogs', 'loyal', 'shine', 'sunrise', 'mtvlaglobalgolden', 'keerthysuresh', 'poetry', 'currently', '8', 'lunch', 'alessandro', 'elena', 'ourboyandgirl', 'peo', 'variety', 'personal', 'opinion', 'valuable', 'jimin', 'jungkook', 'preciou', '13', 'hurting', 'superheros', 'travelexploria', 'weekends', 'mazel', 'tov', 'coach', 'bride', 'hugs', 'mourn', 'pal', 'daisy', 'la', 'abba', 'although', 'separated', 'lexi', 'journey', 'triumph', 'spreading', 'hype', 'etika', 'beautif', '60', 'terribly', 'painful', 'loyalty', 'security', 'chefs', 'magazine', 'editor', 'nuestlove', 'coolest', 'princewilliam', 'protects', 'putting', 'reading', 'tweet', 'bubbly', 'swell', 'mindset', 'maturity', 'parade', 'drown', 'sadness', 'goin', 'sour', 'straying', 'ending', 'kyle', 'echarri', '18thbdaysalubong', 'landon', 'paralegal', 'san', 'francisco', 'hairdresser', 'change', 'glorious', 'offline', 'thinking', 'inspires', 'carefree', 'happily', 'ian', 'bb', 'astro', 'honey', 'unlived', 'tragic', 'sound', 'short', 'iam', 'upliftworld', 'wild', '50th', 'greatful', 'hyukjae', 'experiencing', 'moms', 'pallavi', 'raghav', 'else', 'worlds', 'tie', 'effortlessly', 'solo', 'shipper', 'madiselgroup', 'madiselcoaching', 'lifecoach', 'quote', 'georgesand', 'grant', 'righteous', 'offspring', 'extremely', 'talented', 'gene', 'junior', 'girls', 'boys', 'sidhearts', 'joined', 'twit', 'fourth', 'layer', 'religion', 'universal', 'infratech', 'goodness', 'donal', 'grey', 'hair', 'trio', 'btss', 'makane', 'line', 'personally', 'mrg', 'b4', 'bored', 'serials', 'entertainment', 'provided', 'riansh', 'rrahel', 'ridhbir', 'vangr', 'mac', 'messy', 'lie', 'trauma', 'eimear', 'humour', 'nurses', 'athens', 'telemarketer', 'athletic', 'seeing', 'soooooo', 'siddi', 'lifes', 'seem', 'excitement', 'rose', 'mustread', '0', 'ah', 'glowing', 'setting', 'saturday', 'lekker', 'mnchwaah', 'reality', 'mako', 'ayaka', 'rio', 'miihi', 'riku', 'nina', 'maya', 'mayuka', 'rima', 'meant', 'inspirationalquotes', 'beyourself', 'partner', 'bf', 'counselor', 'hubby', 'providin', 'heartwarming', 'endearing', 'reallifehero', 'via', 'desi', 'tracks', 'volume', 'cover', 'flowers', 'evil', 'mangaka', 'student', 'seiich', 'bro', 'giggle', 'selfcare', 'loveyourself', 'kodrea', 'starmagicblackpenday', 'mutuals', 'recommended', 'bimbo', 'mature', 'finding', 'toughest', 'somone', 'youu', 'ill', 'dudoy', 'maligayangkaarawan', 'happybirthday', 'goodvibes', 'quezon', 'phi', 'couldnt', 'snuggle', 'signif', '230', 'stage', 'agai', 'mytechie', 'royal', 'saving', 'knowing', 'tattoo', '8851', 'diego', 'ross', 'emily', 'possession', 'profoundness', 'com', 'schedule', 'ryusei', 'kainuma', 'bbzfamily', 'friendships', 'covid', 'allha', 'ldh', '22nd', 'succe', 'mi', 'enj', 'cous', 'challenge', 'ace', 'gotchu', 'cst', 'spark', 'broke', 'shall', 'beach', 'paul', 'mccartney', 'cody', 'brandi', 'theyll', 'squeeze', 'tight', 'sandy', 'mezzauntie', 'adn', 'trending', 'pair', 'shopping', 'laughte', 'promise', 'obtain', 'satisfy', 'wit', 'searching', 'mavi', 'reconciled', 'expand', 'individual', 'insurance', 'singlemom', 'jenny', 'turne', 'list', 'adoration', 'kurt', 'kobain', 'heath', 'beautifully', 'written', 'novel', 'grab', 'copy', 'rewrite', 'sta', 'capitalism', 'suck', 'bit', 'production', 'die', 'concept', 'explain', 'bab', 'terrible', 'bearing', 'scar', 'automatically', 'disqualify', 'fut', 'destined', 'depressed', 'poor', 'giant', 'sucess', 'ameen', 'ssrians', 'ssr', '79th', 'pic', 'expected', 'id', 'happier', 'therapy', 'therapist', 'asshole', 'admit', 'baji', 'ok', '22yrs', 'classic', 'hddcs', 'wau', 'japan', 'justin', 'deb', 'barlow', 'detailxperts', 'grade', 'deeply', 'allow', 'mingle', 'issue', 'failure', 'wil', 'chuuya', 'oxy', 'ikon', 'healed', 'edify', 'increase', 'selfworth', 'hint', 'dekhte', 'rahiye', 'janani', 'sirf', 'ishara', 'zindagi', 'nazara', 'pa', 'cinematic', 'perfection', 'culture', 'sho', 'proudly', 'received', 'eve', '34', 'mrsmoke', 'kristi', 'astral', 'wrapping', 'acceptance', 'infatuated', 'fell', 'personali', 'magic', 'marypoppins', 'disneymovies', 'repeated', 'pattern', 'police', 'officers', 'tedious', 'inner', 'nb', 'mewgulf', 'helped', 'realise', 'dem', 'official', 'owner', 'sold', 'u0001f972', 'friday', 'watching', 'hahahaha', 'kaayo', 'akong', 'karun', 'mike', 'breathtaking', 'bookstore', 'managing', 'spent', 'shot', 'drunk', 'transition', 'cade', 'lasting', 'falling', 'rea', 'shanghai', 'rhiannon', 'gallery', 'wished', 'goa', 'smell', 'fathersdayatgardencity', 'jungle', 'actually', 'france', 'alana', 'ta', 'statement', 'fulfillment', 'exols', 'kaye', 'strange', 'doubt', 'managed', 'achieve', 'white', 'assalam', 'alaekum', 'frown', 'weakness', 'anxious', 'purple', 'swept', 'foot', 'equal', '50', 'bravest', 'benevolence', 'becomes', 'beast', 'baddest', 'mystery', 'magical', 'futur', 'halala', 'culxurezw', 'poet', 'musician', 'creative', 'entrepreneur', 'bir', 'looked', 'earnest', 'lip', 'rad', 'consist', 'cherishing', 'thankyoudad', '71st', 'nay', 'chee', 'jimins', 'blatantly', 'thrown', 'victorious', 'sendithome', 'charactersshapedbygenerations', 'definitely', 'apprec', 'crush', 'broken', 'ijumaa', 'kareem', 'frien', 'happiiee', 'bakhiiiiiiii', 'greeting', 'innalillah', '30', 'valorant', 'fix', 'run', 'gun', 'diagnosed', 'arrival', 'survived', 'twelve', 'tip', 'ride', 'remembering', 'psychiatrist', 'perscribed', 'adhd', 'med', 'cancele', 'sadly', 'narcism', 'behavior', 'abusive', 'rather', 'recently', 'bipolar', 'disorder', 'manic', 'medication', 'treatment', 'cofacilitate', 'presentation', 'crowd', '40', 'officially', 'gad', 'ocd', 'medical', 'record', 'lmao', 'seeking', 'psych', 'likely', 'antidepressant', 'however', 'properly', 'obvious', 'misunderstood', 'function', 'differently', 'female', 'rant', 'severe', 'anxiety', 'slight', 'panic', 'attack', 'zach', '20', 'autism', 'fe', 'schizophrenia', 'borderline', 'personality', 'disassociative', 'disor', 'functioning', 'woooooo', 'clinically', 'possibly', 'few', 'hearing', 'album', 'ripe', '14', 'jordan', 'hon', 'evaluated', 'selfdiagnosed', 'mention', 'rushed', 'professional', 'shit', 'theyd', 'diagnose', 'pare', 'spender', 'pocket', 'told', 'lfg', 'bitch', 'zoloft', 'xanax', 'apparently', 'marker', 'mono', 'assume', 'doc', 'ptsd', 'roll', 'post', 'knowin', 'hibs', 'update', 'mentally', 'relax', 'stream', 'whenever', 'tbh', 'swag', '2018', 'clinical', 'caused', 'repressed', 'menshealthweek', 'remembered', 'joke', 'million', 'suffer', 'half', '2x', 'forced', 'abortion', '18', 'raped', 'chi', 'buck', 'eddie', 'checked', 'yay', 'disappoints', '4th', 'disord', 'finished', 'nurological', 'test', 'sooo', 'tired', 'puzzle', 'block', 'annie', 'sammy', 'eating', 'formally', 'major', 'def', 'changer', 'near', 'asd', 'medically', 'struggled', 'dennis', 'omba', 'steroidinduced', 'diabetes', 'metformin', 'walked', 'diagnosis', 'possible', 'nevermind', 'waaaay', 'acknowledged', 'honest', 'yeah', 'coloured', 'cuz', 'freaking', 'ugly', 'nev', 'unfortunately', 'common', 'antidepressants', 'sativas', 'was', 'recognized', 'prescribed', 'disease', 'fighting', 'bet', 'billion', 'office', 'realize', 'poorly', 'handled', 'supportive', 'breakup', 'introver', 'moderate', 'lmfao', 'refuse', 'counsellor', 'generalised', 'mixed', 'emotio', 'someo', 'tune', 'tonight', 'director', 'kopell', 'colleague', 'refusuez', 'seve', 'char', 'tried', 'dump', 'kidding', 'derealisation', 'yep', 'dissociate', 'regularly', 'practicing', 'vulnerability', 'correctly', 'rcpsychic', 'reared', 'luckily', 'lockdown', 'talking', 'pandemic', 'studying', 'diag', 'arena', '2019', 'accepted', 'undiagnosed', '25', 'causin', 'illness', 'cancer', 'bone', 'medica', 'nyo', 'ko', 'sobrang', 'makakatulong', 'introduction', 'vent', 'ednos', 'afraid', 'counselling', 'scarred', 'dia', 'emergency', 'fancy', 'academic', 'expressing', 'symptom', 'easily', 'worse', 'thousand', 'employed', 'fill', 'dass', 'directly', 'fight', 'telling', 'waste', 'tw', 'suspected', 'dysmorphia', 'class', 'develop', 'tit', 'har', 'window', 'clothes', 'online', 'damb', 'lifestyle', 'causing', 'socalled', 'expansive', 'insomnia', 'antisocial', 'bpd', 'anxi', 'havent', 'duloxetine', 'young', 'scheduled', 'appointment', 'nearest', 'generalized', 'medicated', 'graduated', 'drs', 'figur', 'carson', '16', 'pronoun', 'aspergers', 'suspect', 'bullied', 'rule', 'meme', 'relatable', 'esp', 'fami', 'spoke', 'newly', 'du', 'sleep', 'tested', 'tsundere', 'semicontrollable', 'necessarily', 'downpla', 'quarterly', 'statemanda', 'begging', 'differ', 'generasi', 'skrg', 'suka', 'katan', 'ither', 'socially', 'withdraw', 'asking', 'hesitate', 'dm', 'specially', 'repeat', '90', '00', 'patient', 'oddly', 'intim', 'lilah', 'myob', 'minor', 'pronouns', 'confused', 'sexuali', 'aged', 'spl', '15', 'benefit', 'hit', 'condition', 'anyon', 'saying', 'turns', 'ass', 'zero', 'interest', 'mild', 'hur', 'dealt', 'pregnant', 'uh', 'hyper', 'later', 'pjsekai', 'miku', 'main', 'pan', 'hypomania', 'kissesdelavin', 'decline', 'patriarchal', 'hegemony', 'parallel', 'rise', 'dnd', 'abl', 'realised', 'coping', 'skill', 'bahahahaa', 'stuggle', 'osdd', 'probably', 'shame', 'peop', 'brain', 'abnorm', 'lvl', 'academically', 'adept', '2017', 'twt', 'depressive', 'pernicious', 'anaemia', 'b12', 'deficiency', 'staggering', 'speeding', 'train', 'overlap', 'depressi', 'decade', 'abuse', 'assed', 'chase', 'hospitalization', 'polarity', 'frightens', 'mania', 'motivationalmonday', 'spotlight', 'pete', 'davidson', 'tgat', 'yoh', 'arent', 'including', 'exact', 'ykk', '37', 'irks', 'depr', 'allowed', 'toddler', 'kick', 'scared', 'mutter', 'depress', 'fair', 'yearold', 'drop', 'study', 'bein', 'speaking', 'staff', 'flint', 'house', 'agreed', 'sprinkle', 'prison', 'sigh', 'color', 'blue', 'lon', 'born', 'psycholo', 'result', 'comprehensive', 'servic', 'accepting', 'als', 'research', 'fou', 'concert', 'choosing', 'fuel', 'reali', 'sat', 'car', 'silence', 'simone', '80', 'dose', 'vaccine', 'sr', 'review', 'goto', 'unwell', 'listening', 'critic', 'case', 'involve', 'disordered', 'habit', 'dreadful', 'immune', 'system', 'constantly', 'pressu', 'sarcopenia', 'geelongosteoporosisstudy', 'suggests', 'low', 'mood', 'affect', 'dysthymia', 'ear', 'fuckin', 'grandfather', 'ran', 'addiction', 'disorde', 'lmaoo', 'damnit', 'suffered', 'sort', 'de', 'guys', 'skip', 'science', 'homoph', 'tend', 'tmr', 'woken', '10ish', 'diso', 'invasive', 'surgery', 'leech', 'suicide', 'loos', 'rare', 'flu', 'rel', 'outright', 'banning', 'diagnos', 'interpret', 'intp', 'prns', 'aries', 'unlabeled', 'agender', 'potentially', 'schizophrenic', 'brug', 'forcing', 'hilarious', 'almost', 'developed', 'ed', 'km', 'se', 'seftdiagnosed', 'nnnnnnnnnnnnn', 'ra', 'apologise', 'behavioral', 'experiment', 'sever', 'suburban', 'push', 'narrative', 'yea', 'facts', 'selective', 'mutism', 'states', 'survivor', 'survivo', '15yrs', 'sah', 'pnd', 'onc', 'happens', 'israeli', 'spy', 'mossad', 'abt', 'connor', '04', 'gender', 'dysphoria', 'tweeting', 'accute', 'kicked', 'blow', 'changingco', 'noooo', 'genius', 'haunting', 'link', 'scie', 'calm', 'join', 'myheartdiseaseteam', 'annoying', 'normal', 'buzzfeed', 'lmaooo', 'tr', 'use', 'internet', 'sweeping', 'generalisation', 'trigger', 'warning', 'shouldnt', 'hindi', 'pwedeng', 'maging', 'dapat', 'matapang', 'lag', 'recovered', 'aggravated', 'nervous', 'buddy', 'custodian', 'wtf', 'throwing', 'initially', 'explained', 'dep', 'fin', 'josh', 'sought', 'thankfully', 'sophie', 'remission', 'deppresion', 'dpdr', 'haan', 'proved', 'farmabardar', 'feroz', 'college', 'refused', 'rainbow', 'smokey', 'laughs', 'debilitating', 'wrongly', 'consider', 'disability', 'doubted', 'escape', 'eighth', 'extrac', 'wording', 'corelate', 'exercise', 'walking', 'prev', 'refuses', 'esa', 'thema', 'neurotypical', 'roller', 'coaster', 'convince', 'smart', 'historical', 'factor', 'cooper', 'village', 'funding', 'credible', 'discovered', 'gross', 'satis', 'somet', 'yoongis', 'verse', 'ad', 'chronic', 'isolation', 'beleive', 'confirmed', 'adding', 'professionally', 'educated', 'aint', 'tryna', 'depressio', 'bdp', 'contemplated', '201', 'faced', 'blown', 'hospitalized', 'cried', 'nobody', 'understands', 'phobia', 'adulthood', 'due', 'acting', 'welp', 'using', 'reaching', 'unless', 'pretentious', 'awareness', 'sabotage', 'spectrum', 'lit', 'jackson', '21', 'neurodivergent', 'depersonalization', 'scary', 'u0001f978', 'whoo', 'hoo', 'otherwise', 'cptsd', 'aspd', '14yrs', 'third', 'diagno', 'yan', 'din', 'yung', 'sabi', 'sa', 'amin', 'ng', 'psychometrician', 'prof', 'namin', 'careful', 'term', 'oook', 'unlike', 'meltdown', 'shutdown', 'sensory', 'overload', 'burnout', 'suicidal', 'none', 'mechanism', 'cop', 'separately', 'victim', 'mentality', 'frustrating', 'transgender', 'activist', 'illegal', 'psychologist', 'deny', 'sugges', 'dollhouse', 'cereal', 'finish', 'str', 'fyi', 'teenager', 'medicine', 'available', 'resistant', 'sense', '23', 'january', 'ungamer', 'psyc', 'similar', 'mai', 'sleeping', 'microdepression', 'woohoo', 'melancholy', 'circumstance', 'town', 'estoy', 'pasando', 'por', 'uno', 'entre', 'comillas', 'pq', 'pero', 'el', 'gotcha', 'speculated', 'vastly', 'suicida', 'mind', 'dismiss', 'scene', 'fine', 'certain', 'critical', 'enemy', 'suddenly', 'depre', 'wreak', 'havoc', 'diagn', 'blogging', 'hardest', 'ii', 'depres', 'recurrent', 'imho', 'adhdmisdiagnosis', 'malpractice', '28', 'referral', 'throwback', 'basically', 'nicole', 'melleby', 'reported', 'attribute', 'bubble', 'approach', 'laughed', 'text', 'phone', 'wri', 'endogenous', 'means', 'stfu', 'btw', 'spurt', 'accord', 'original', 'po', 'anx', 'listen', 'playlist', 'psd', 'proof', 'iatrist', 'ologist', 'wrote', 'ia', 'bac', 'silent', 'hyperthyroidism', 'asked', 'noticed', 'clinic', 'undetected', 'plenty', 'prove', 'opposing', 'adoption', 'labeled', 'whic', 'euphoric', 'freed', 'anorexia', 'prbly', 'bye', 'introverted', 'meanwhile', 'classmate', 'extro', 'type', '2020', 'camhs', 'referred', 'suic', '17', 'kinda', 'processing', 'info', 'psychotic', 'dealing', 'anymore', 'scored', 'higher', 'icide', 'rate', 'inferiority', 'complex', 'lmk', 'coped', 'sudden', 'confusing', 'catherine', 'middleton', 'counseling', 'total', 'mess', 'vietnam', 'messed', 'prone', 'youngest', 'magically', 'sumn', 'und', 'fift', 'si', 'nd', 'ud', 'lolll', 'worry', 'stigma', 'couldn', 'sexy', 'dk', 'crashed', 'olympic', 'champion', 'manuel', 'reveals', 'overtraining', 'syndrome', 'hyuna', 'featured', 'conversation', 'symptoms', 'pressure', 'december', 'lrt', 'inaccuracy', 'highlight', 'include', 'misdx', 'priori', 'offense', 'differen', 'treating', 'admin', 'intro', 'strider', 'rp', 'streets', 'earlier', 'stopped', 'random', 'boi', '2012', 'six', 'mentioned', 'effect', 'overwhelmed', 'lead', 'pas', 'clinicall', 'recovery', 'hospital', 'sent', '33', 'misdiagn', 'boarding', '36', 'resea', 'gunned', 'originally', 'sen', 'tourettes', 'applaud', 'posting', '56', 'manager', 'jobless', 'seven', 'funct', 'witnessk', 'court', 'canberra', 'sentence', 'imprisonment', 'wholly', 'suspended', 'entering', 'psvt', 'normally', 'mistake', 'several', 'dropped', 'picked', 'pushing', 'hes', 'collect', 'decide', 'active', 'fails', 'straight', 'eligible', 'medicaid', 'letter', 'era', 'rough', 'spot', 'destigmatize', 'federal', 'disabili', 'disclaimer', 'booo', 'ext', 'taco', 'hell', 'volcano', 'burrito', 'dis', 'doorknob', 'door', 'bi', 'polar', 'therefore', 'excuse', 'cide', 'process', 'int', 'funk', 'pls', 'ti', 'presented', 'migraine', 'decent', 'walk', 'tories', 'commo', 'seasonal', 'summertime', 'u0001f9a9', 'battled', 'mdd', 'crippling', 'miserable', 'gerd', 'considering', 'anxiet', 'explicitly', 'streaming', 'teaching', 'dance', 'cronic', 'cli', 'mf', 'candace', 'owens', 'tbf', 'tumblr', 'grad', 'mjr', 'oc', 'icymi', 'adolescent', 'specifically', 'increased', 'hypochondriac', 'legit', 'nurse', 'practitioner', 'mys', 'design', 'illnes', 'lectured', 'accountable', 'scolding', 'heeding', 'advice', 'aggressive', 'space', 'negativity', 'ana', 'unfaithful', 'rihanna', 'writing', 'accompanied', 'buzzword', '7th', 'diagnostic', 'exam', 'coworkers', 'tol', 'bulimia', 'called', 'apsychotic', 'psychosis', 'clic', 'multiple', 'abnormal', 'series', 'sucked', 'hockey', 'venturefunding', 'healthtech', 'startup', 'skyrocket', 'thi', 'unofficially', 'abroad', 'included', 'jfc', 'draw', 'aren', 'commit', 'oldest', 'moved', 'opened', 'brad', 'pitt', 'allegedly', 'according', 'weekly', 'ph', 'rothbaum', 'endstigma', 'techically', 'virtue', 'signaling', 'finest', 'candidate', 'legalize', 'psychedelics', 'besties', 'controversial', 'topic', 'gravity', 'accused', 'sand', 'slit', 'upset', 'unscientific', 'bald', 'gained', 'gaining', 'raised', 'standard', 'failed', 'orgo', 'mercy', 'depending', 'nak', 'sikit', 'semua', 'orang', 'masa', 'akan', 'rasa', 'beza', 'dengan', 'bu', 'bullet', 'fatal', 'aware', 'stalker', 'aw', 'ohio', 'website', 'evaluatio', 'faked', '247', 'cbd', 'cbdoil', 'psycho', 'blame', 'local', 'officer', 'recommending', 'trea', 'arc', 'amalgamation', 'nah', 'paranoia', 'statistic', 'basic', '2534', 'shits', 'stressed', 'busy', 'burnouts', 'meltdowns', 'harder', 'te', 'pun', 'takaful', 'industry', 'cash', 'relief', 'anxie', 'phase', 'vanished', 'damn', 'difference', 'harmless', 'outrigh', 'dah', 'tak', 'macam', 'dulu', 'curious', 'average', 'eight', 'ten', 'pass', 'emerge', 'jus', 'byproduct', '6yrs', 'suffers', 'quite', 'diabetesawarenessweek', 'psychological', 'passed', 'laziness', 'precursor', 'yup', 'variously', 'agoraphobia', 'reactive', 'popping', 'xanny', 'tendency', 'forgive', 'missed', 'gps', 'hyperactivity', 'hospitalisati', 'difficulty', '1999', 'addict', 'selfharmer', 'wilbursoot', 'singing', 'nihachu', '2005', 'uk', 'facing', 'faking', 'ring', 'bell', 'um', 'anon', 'lack', 'creativity', 'havi', 'target', 'demographic', 'dt', 'ash', 'shtwt', 'ig', 'interacts', 'edtwt', 'upse', 'pkp', 'toll', 'vitam', 'becker', 'lmfaoo', 'situational', '1a', 'mainly', '67', 'brief', 'roughly', 'bei', 'sang', 'bish', 'cr', 'aired', 'vital', 'november', 'quiz', 'gi', 'joker', 'hopefully', 'owe', 'commission', 'slow', 'spongebob', 'simpson', 'edits', 'offended', 'refer', 'reflects', 'targeting', 'discrimination', 'unusual', 'angle', 'achieved', 'diamond', 'status', '19', 'haul', 'incre', 'anorexic', 'option', 'psychiatri', 'misalignment', 'explains', 'interview', 'reveal', 'anyways', 'whew', 'moreso', 'impression', 'farming', 'hottest', 'sliced', 'perhaps', 'ignorance', 'bliss', 'chest', 'exhausted', 'combination', 'gp', 'doi', 'venting', 'anyway', 'barely', 'stanley', 'arktaev', 'advised', 'affectionately', 'calling', 'gifted', 'behold', 'ophelia', 'adopted', 'visited', 'session', 'pulled', 'waiting', 'mode', 'gnna', 'paralysis', 'percent', 'carry', 'abilify', 'benzatropine', 'spelling', 'dysph', 'employer', 'stupid', 'diagnosing', 'edgy', 'begin', '1987', 'panromantic', 'demiromantic', 'genderqueer', 'specializes', 'clear', 'guilty', 'conscio', 'burden', 'neil', 'darkness', 'latest', 'psychologic', 'report', 'dark', 'u0001f9cd', 'lancet', '47', 'highdistress', 'phenotype', 'cohort', 'indication', 'untreated', 'seems', 'impossible', 'hormones', 'experts', 'hontent', 'slightly', 'cope', 'blamed', 'hormone', 'sounds', 'unlockyourstory', 'campaign', 'intan', 'maisara', 'stans', 'explaining', 'mask', 'rhyme', 'lalo', 'nung', 'danganronpa', 'donkey', 'kong', 'abo', 'eat', 'mark', 'dissatisfac', 'developmental', 'delayed', 'disappeared', 'workplace', 'commonly', 'moderatesevere', 'ngl', 'han', 'entitled', 'compe', 'becaus', '2day', 'battle', 'exhausting', 'tuberculosis', 'initiation', 'among', 'botswana', 'competition', 'vicious', 'cycle', 'medicat', 'reclaim', 'fire', 'sustained', 'either', 'aunt', 'saddest', 'superstar', 'ignored', 'amcstory', 'onto', 'fml', 'unh', 'mun', 'tends', 'distracted', 'cell', 'dominance', 'eith', '2013', 'favorite', '1314', 'selfdiagnose', 'tches', 'july', '24th', 'following', 'adhdtwitter', '44', 'mana', 'recommend', 'drew', 'gf', 'shell', 'grandmother', 'buries', 'ssi', 'fmla', 'webtoon', 'author', 'korea', 'bothered', 'translation', 'thei', 'application', 'throw', 'bounced', 'forth', 'st', 'secluding', 'questioning', 'scoliosis', 'arti', 'serious', 'bout', 'alth', '20102018', '124', 'committed', 'rocker', 'odd', 'badly', 'epilepsy', 'whos', 'smith', 'documentary', 'app', 'hashimotos', 'toying', 'majordepressivedisorder', 'male', 'researcher', 'foun', 'disregard', 'ignoring', 'hrt', 'tiktok', 'hmph', 'scan', 'housemate', 'hv', 'wondered', 'issues', 'danish', 'odds', 'smallcell', 'lung', 'gymnastics', 'extent', 'generaliz', 'boom', 'sends', 'lash', 'fault', 'lose', 'purpose', 'direction', 'eventuall', 'further', 'sympt', 'experien', 'jumped', 'bandwagon', 'clearly', 'versus', 'interaction', 'control', 'shock', 'difficu', 'nonbinary', 'australian', 'korang', 'expression', 'rsd', 'alfie', 'templeman', 'unmotivated', 'internship', 'g', 'newcastle', 'sue', 'politician', 'screwed', 'economically', 'convinced', 'greatly', 'reduce', 'num', 'service', 'medicati', 'overview', 'materialistic', 'polyamory', 'drus', 'user', 'pills', 'aspergeric', 'receiving', 'cdb', 'oil', 'appar', 'acha', 'gl', 'qualifie', 'served', 'cunt', 'hrgh', 'drawing', 'traumatic', 'shocked', 'worsen', 'dknt', 'undo', 'fucjing', 'horny', 'hasn', 'sign', 'appt', 'wei', 'vocal', 'mute', 'frequently', 'merch', 'effe', 'piff2021doc', 'quietly', 'attempted', 'alt', 'ate', 'hw', 'divorced', 'dragon', 'coin', 'complaint', 'petras', 'ratio', 'attempt', 'cryi', 'credit', 'relating', 'misato', 'advocate', 'tv', 'pil', 'doctors', 'para', 'flag', 'lately', 'touc', 'drain', 'bo', 'trip', 'worried', 'lik', 'izzi', 'intellectual', 'potential', 'highly', 'emotiona', 'starter', 'pack', 'memes', 'starterpack', 'stric', 'commented', 'flora', 'occasionally', 'healthawareness', 'nos', 'sympto', 'heds', 'gastoparilisis', 'mcas', 'lyme', 'tietze', 'pots', 'scare', 'disliking', 'addictive', 'behaviour', 'root', 'excellent', 'accessible', 'gabor', 'mat', 'assessment', 'contagion', 'stressrelated', 'dec', 'dysthmia', 'persistent', 'continuous', 'longterm']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmNXuyVliCI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "225a7a34-deeb-41b8-f651-ab729692bd96"
      },
      "source": [
        "model.wv.most_similar('depression')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('diagnosed', 0.9999277591705322),\n",
              " ('wa', 0.9999120235443115),\n",
              " ('anxiety', 0.999897301197052),\n",
              " ('with', 0.9998953342437744),\n",
              " ('been', 0.999894380569458),\n",
              " ('i', 0.9998931884765625),\n",
              " ('got', 0.9998847246170044),\n",
              " ('adhd', 0.9998801946640015),\n",
              " ('disorder', 0.9998561143875122),\n",
              " ('just', 0.9998427629470825)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EBxCSIe2sxy"
      },
      "source": [
        "Saving the word2vec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZnauC_OmInN"
      },
      "source": [
        "filename = 'tweets_embedding.txt'\n",
        "model.wv.save_word2vec_format(filename,binary=False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b21TlBd_xzAo"
      },
      "source": [
        "Preparing Train and Test Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi9BjL-WczkS"
      },
      "source": [
        "def prep_tokenizer(tweet_list):\n",
        "    #instantiating the tokenizing object -creating a unique word dictionary ,where unique words are rep. as sentences\n",
        "    tokenizer = Tokenizer()\n",
        "    #fitting it into the text\n",
        "    tokenizer.fit_on_texts(tweet_list)\n",
        "    #saving the tokenizing object\n",
        "    with open('tokenizer.pickle', 'wb') as handle:\n",
        "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        print('Tokeniser saved')\n",
        "    \n",
        "def prepare_data(tweet_list,tokenizer):\n",
        "   #creating a list of tokens for each tweet (A list of lists)\n",
        "   sequences = tokenizer.texts_to_sequences(tweet_list)\n",
        "   word_index = tokenizer.word_index\n",
        "   print('Vocabulary size:', len(word_index))\n",
        "   max_length = max([len(s.split()) for s in tweets])\n",
        "   tweet_pad =pad_sequences(sequences,maxlen=max_length)\n",
        "   return tweet_pad\n",
        "\n",
        " "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y618PXpIsd0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c44273-9261-4db6-ab89-94b2b2cf0df3"
      },
      "source": [
        "import pickle \n",
        "import os\n",
        "import re\n",
        "\n",
        "prep_tokenizer(tweet_list)\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "   tokenizer = pickle.load(handle)\n",
        "\n",
        "tweet_pad = prepare_data(tweet_list,tokenizer)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokeniser saved\n",
            "Vocabulary size: 4381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGNU4I1M50TW"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(tweet_list)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwlO4vIYRyp3"
      },
      "source": [
        "emotion_score=data['depression_score'].values\n",
        "VALIDATION_SPLIT = 0.2\n",
        "indices = np.arange(tweet_pad.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "tweet_pad = tweet_pad[indices]\n",
        "emotion_score = emotion_score[indices]\n",
        "\n",
        "num_validation_samples = int(VALIDATION_SPLIT * tweet_pad.shape[0])\n",
        "\n",
        "x_train_pad = tweet_pad[:-num_validation_samples]\n",
        "y_train = emotion_score[:-num_validation_samples]\n",
        "x_test_pad = tweet_pad[-num_validation_samples:]\n",
        "y_test = emotion_score[-num_validation_samples:]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axq4niqswduR"
      },
      "source": [
        "emotion_score=data['label'].values\n",
        "\n",
        "VALIDATION_SPLIT = 0.2\n",
        "indices = np.arange(tweet_pad.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "tweet_pad = tweet_pad[indices]\n",
        "emotion_score = emotion_score[indices]\n",
        "\n",
        "num_validation_samples = int(VALIDATION_SPLIT * tweet_pad.shape[0])\n",
        "\n",
        "x_train_pad = tweet_pad[:-num_validation_samples]\n",
        "y_train = emotion_score[:-num_validation_samples]\n",
        "x_test_pad = tweet_pad[-num_validation_samples:]\n",
        "y_test = emotion_score[-num_validation_samples:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMRmKnCb10T7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ecada57-f0e7-40be-98af-3df45cfee1ca"
      },
      "source": [
        "x_train_pad = np.asarray(x_train_pad).astype(np.float32)\n",
        "y_train = np.asarray(y_train).astype(np.float32)\n",
        "x_test_pad = np.asarray(x_test_pad).astype(np.float32)\n",
        "y_test= np.asarray(y_test).astype(np.float32)\n",
        "\n",
        "\n",
        "print(len(x_test_pad))\n",
        "print(len(x_train_pad))\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "380\n",
            "1524\n",
            "1524\n",
            "380\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKvQ4OIwTNZA",
        "outputId": "bc6498fe-29fd-4b82-897b-336b8699cecb"
      },
      "source": [
        "import collections, numpy\n",
        "print(collections.Counter(y_train))\n",
        "print(collections.Counter(y_test))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({48.109: 23, 2.5: 21, 0.0: 17, 21.0015: 7, 8.21: 7, 47.7325: 6, 24.932: 5, 63.5975: 4, 7.5: 4, 47.14: 4, 47.155: 4, 335.9425: 4, 3.5: 4, 47.57: 4, 129.025: 4, 48.16: 4, 47.2075: 4, 81.892: 4, 47.275: 4, 128.96: 3, 47.645: 3, 47.1875: 3, 46.4575: 3, 11.35: 3, 33.4235: 3, 23.766: 3, 73.161: 3, 47.8425: 3, 49.312: 3, 63.6245: 3, 47.3025: 3, 82.8485: 2, 48.46: 2, 41.103: 2, 9.253: 2, 140.655: 2, 35.7975: 2, 47.5075: 2, 47.41: 2, 67.146: 2, 41.42: 2, 47.9825: 2, 35.8595: 2, 50.295: 2, 128.9075: 2, 131.0725: 2, 6.07: 2, 4.2855: 2, 58.3955: 2, 47.4305: 2, 50.8725: 2, 26.224: 2, 32.902: 2, 27.7575: 2, 26.3995: 2, 24.1995: 2, 47.1175: 2, 22.2385: 2, 53.9695: 2, 21.2405: 2, 63.805: 2, 47.25: 2, 21.021: 2, 34.7015: 2, 48.3345: 2, 128.9325: 2, 24.911: 2, 61.345: 2, 4.64: 2, 131.0475: 2, 44.5225: 2, 7.9595: 2, 48.0625: 2, 71.0475: 2, 51.14: 2, 20.965: 1, 19.4075: 1, 97.265: 1, 143.451: 1, 128.892: 1, 92.3125: 1, 18.8015: 1, 51.072: 1, 16.63: 1, 52.86: 1, 21.2015: 1, 90.364: 1, 9.0035: 1, 133.6895: 1, 49.008: 1, 224.275: 1, 32.0255: 1, 54.488: 1, 35.513: 1, 12.033: 1, 19.027: 1, 48.011: 1, 17.0945: 1, 49.7715: 1, 74.9435: 1, 139.9375: 1, 38.3835: 1, 65.4665: 1, 75.4245: 1, 79.377: 1, 48.856: 1, 52.85: 1, 55.339: 1, 188.51: 1, 25.6255: 1, 11.7615: 1, 24.8935: 1, 18.06: 1, 35.995: 1, 16.2845: 1, 131.8005: 1, 173.94: 1, 135.1225: 1, 130.7775: 1, 21.8965: 1, 31.5985: 1, 24.268: 1, 35.483: 1, 128.8425: 1, 95.6025: 1, 108.606: 1, 94.2885: 1, 110.7115: 1, 129.1465: 1, 56.431: 1, 45.4695: 1, 3.015: 1, 47.6075: 1, 144.3725: 1, 14.838: 1, 186.9595: 1, 168.765: 1, 17.154: 1, 71.71: 1, 130.2075: 1, 130.6625: 1, 88.653: 1, 30.1475: 1, 6.3365: 1, 129.895: 1, 22.4985: 1, 125.038: 1, 25.91: 1, 47.6685: 1, 25.2725: 1, 48.305: 1, 61.573: 1, 233.5975: 1, 51.201: 1, 123.2225: 1, 84.985: 1, 32.692: 1, 12.651: 1, 66.17: 1, 156.4025: 1, 106.9165: 1, 128.8245: 1, 58.0815: 1, 116.666: 1, 48.241: 1, 14.0235: 1, 93.466: 1, 21.224: 1, 43.283: 1, 48.2895: 1, 30.9065: 1, 76.0765: 1, 11.631: 1, 37.573: 1, 137.2725: 1, 47.4525: 1, 61.3765: 1, 23.379: 1, 16.124: 1, 33.4685: 1, 135.1925: 1, 166.5365: 1, 31.102: 1, 156.3775: 1, 224.224: 1, 35.064: 1, 29.7: 1, 44.865: 1, 80.9775: 1, 103.0725: 1, 174.2235: 1, 21.731: 1, 32.448: 1, 7.0075: 1, 42.169: 1, 128.08: 1, 21.6215: 1, 43.724: 1, 24.6745: 1, 47.3225: 1, 22.5415: 1, 36.01: 1, 61.6245: 1, 93.6425: 1, 28.602: 1, 60.035: 1, 18.0085: 1, 49.7835: 1, 9.339: 1, 102.7475: 1, 28.0425: 1, 46.7685: 1, 31.625: 1, 60.51: 1, 18.3185: 1, 16.896: 1, 17.7485: 1, 86.8255: 1, 15.935: 1, 5.671: 1, 131.7155: 1, 32.8805: 1, 19.962: 1, 49.2925: 1, 80.0315: 1, 52.102: 1, 103.7125: 1, 31.7645: 1, -1.1325: 1, 165.3475: 1, 95.34: 1, 47.7805: 1, 63.565: 1, 52.2795: 1, 51.629: 1, 31.6035: 1, 72.1975: 1, 92.28: 1, 48.0235: 1, 88.685: 1, 107.0335: 1, 11.22: 1, 124.3605: 1, 120.7025: 1, 72.4915: 1, 56.159: 1, 105.127: 1, 10.8235: 1, 151.654: 1, 45.8825: 1, 11.178: 1, 14.654: 1, 72.645: 1, 17.7325: 1, 206.175: 1, 276.1115: 1, 13.6695: 1, 62.5125: 1, 47.6925: 1, 18.111: 1, 137.9475: 1, 18.412: 1, 58.67: 1, 24.149: 1, 218.9725: 1, 140.0675: 1, 92.0125: 1, 40.8525: 1, 20.19: 1, 235.465: 1, 36.7515: 1, 131.698: 1, 16.069: 1, 95.81: 1, 130.491: 1, 47.19: 1, 62.405: 1, 18.003: 1, 29.467: 1, 66.7175: 1, 48.2315: 1, 34.1585: 1, 136.414: 1, 8.03: 1, 141.67: 1, 69.125: 1, 48.412: 1, 50.743: 1, 49.8955: 1, 73.725: 1, 20.1695: 1, 17.131: 1, 9.6715: 1, 25.9235: 1, 23.423: 1, 130.7225: 1, 68.696: 1, 14.8155: 1, 168.627: 1, 5.314: 1, 95.0575: 1, 89.023: 1, 38.622: 1, 62.7015: 1, 127.7285: 1, 31.788: 1, 48.032: 1, 20.674: 1, 50.972: 1, 207.0175: 1, 36.44: 1, 11.0325: 1, 100.0595: 1, 17.8535: 1, 12.1975: 1, 100.97: 1, 113.195: 1, 45.975: 1, 29.264: 1, 26.4275: 1, 79.6755: 1, 154.0225: 1, 18.92: 1, 35.189: 1, 48.049: 1, 226.035: 1, 100.993: 1, 129.8825: 1, 65.003: 1, 39.983: 1, 8.215: 1, 35.3595: 1, 91.279: 1, 7.898: 1, 14.7885: 1, 39.012: 1, 5.807: 1, 53.202: 1, 53.0635: 1, 115.143: 1, 52.1635: 1, 7.3805: 1, 39.688: 1, 31.4745: 1, 20.733: 1, 35.6115: 1, 48.2075: 1, 46.9125: 1, 3.3215: 1, 31.542: 1, 6.913: 1, 57.9925: 1, 48.6245: 1, 44.511: 1, 173.595: 1, 27.215: 1, 44.3055: 1, 18.1755: 1, 20.329: 1, 99.05: 1, 28.6535: 1, 38.758: 1, 55.574: 1, 52.2075: 1, 49.6255: 1, 43.246: 1, 132.495: 1, 142.209: 1, 50.8035: 1, 140.9535: 1, 27.4335: 1, 56.0835: 1, 46.368: 1, 50.595: 1, 55.279: 1, 67.761: 1, 4.939: 1, 12.724: 1, 45.5825: 1, 10.738: 1, 4.236: 1, 24.589: 1, 110.2825: 1, 24.4065: 1, 126.4775: 1, 62.7435: 1, 133.825: 1, 61.3165: 1, 91.0715: 1, 21.8105: 1, 34.8255: 1, 49.193: 1, 27.351: 1, 88.0655: 1, 22.909: 1, 54.5025: 1, 77.0095: 1, 0.8525: 1, 5.155: 1, 18.3165: 1, 48.977: 1, 21.292: 1, 26.912: 1, 57.14: 1, 115.733: 1, 50.2205: 1, 127.2975: 1, 238.52: 1, 42.028: 1, 8.088: 1, 173.5975: 1, 100.3435: 1, 34.2115: 1, 155.1575: 1, 21.9845: 1, 143.8835: 1, 18.341: 1, 34.9905: 1, 157.1225: 1, 64.0695: 1, 52.2735: 1, 32.278: 1, 88.1575: 1, 44.99: 1, 75.479: 1, 50.3025: 1, 35.503: 1, 135.1435: 1, 50.518: 1, 17.006: 1, 41.617: 1, 147.23: 1, 13.2965: 1, 31.834: 1, 71.1355: 1, 42.374: 1, 23.659: 1, 46.132: 1, 139.6495: 1, 0.7105: 1, 27.6095: 1, 229.663: 1, 104.7225: 1, 3.5345: 1, 17.7085: 1, 6.957: 1, 65.765: 1, 76.1125: 1, 115.8445: 1, 22.8225: 1, 54.4295: 1, 26.4815: 1, 10.1145: 1, 44.4575: 1, 84.7445: 1, 128.985: 1, 17.191: 1, 58.025: 1, 107.7545: 1, 220.7275: 1, 56.523: 1, 80.072: 1, 26.354: 1, 32.274: 1, 90.7275: 1, 112.94: 1, 14.6015: 1, 153.743: 1, 26.768: 1, 93.1915: 1, 129.08: 1, 39.466: 1, 130.765: 1, 5.64: 1, 8.6765: 1, 37.9325: 1, 20.295: 1, 58.4425: 1, 24.8075: 1, 178.4125: 1, 65.47: 1, 139.034: 1, 140.5525: 1, 29.7935: 1, 48.9575: 1, 73.5925: 1, 159.4775: 1, 50.8785: 1, 48.4845: 1, 30.407: 1, 115.808: 1, 50.6505: 1, 59.9275: 1, 104.2525: 1, 16.8395: 1, 76.844: 1, 18.112: 1, 48.8615: 1, 26.832: 1, 5.465: 1, 128.404: 1, 45.92: 1, 12.5735: 1, 81.402: 1, 109.597: 1, 18.5335: 1, 36.355: 1, 11.376: 1, 106.541: 1, 104.0075: 1, 12.35: 1, 48.662: 1, 160.4355: 1, 123.4295: 1, 42.6375: 1, 20.9155: 1, 26.887: 1, 68.647: 1, 50.5035: 1, 22.462: 1, 63.298: 1, 148.2925: 1, 78.8605: 1, 60.512: 1, 34.0975: 1, 46.4: 1, 49.594: 1, 36.4635: 1, 29.384: 1, 39.353: 1, 75.0915: 1, 38.442: 1, 34.6435: 1, 43.09: 1, 131.9795: 1, 26.47: 1, 14.21: 1, 230.81: 1, 44.765: 1, 31.9615: 1, 132.306: 1, 24.065: 1, 48.1895: 1, 145.6275: 1, 10.1835: 1, 177.029: 1, 7.0625: 1, 224.805: 1, 119.8895: 1, 49.1165: 1, 129.852: 1, 8.1745: 1, 26.7285: 1, 49.92: 1, 85.069: 1, 259.8885: 1, 9.285: 1, 138.6375: 1, 56.887: 1, 106.5895: 1, 51.6035: 1, 3.344: 1, 47.7285: 1, 50.4805: 1, 28.509: 1, 51.0375: 1, 39.534: 1, 52.8825: 1, 79.8075: 1, 24.387: 1, 13.368: 1, 29.4475: 1, 60.277: 1, 176.7235: 1, 52.6475: 1, 24.8325: 1, 48.8365: 1, 44.2005: 1, 76.679: 1, 267.445: 1, 45.5885: 1, 52.8095: 1, 65.9585: 1, 9.34: 1, 34.595: 1, 30.873: 1, 57.347: 1, 35.4975: 1, 65.3795: 1, 16.7825: 1, 70.9825: 1, 47.42: 1, 59.82: 1, 141.45: 1, 25.0965: 1, 176.85: 1, 84.29: 1, 47.8375: 1, 128.187: 1, 128.37: 1, 5.8475: 1, 47.4695: 1, 28.675: 1, 32.81: 1, 112.106: 1, 120.085: 1, 2.265: 1, 47.1275: 1, 36.2385: 1, 25.754: 1, 56.3475: 1, 11.358: 1, 52.1405: 1, 131.5975: 1, 61.5385: 1, 132.5575: 1, 75.8325: 1, 48.9635: 1, 158.9: 1, 16.577: 1, 14.578: 1, 9.795: 1, 19.6895: 1, 151.1075: 1, 85.7525: 1, 48.528: 1, 105.64: 1, 20.2835: 1, 9.3355: 1, 34.1125: 1, 14.4125: 1, 58.5905: 1, 142.7725: 1, 12.06: 1, 78.6755: 1, 33.407: 1, 252.3475: 1, 93.6575: 1, 78.48: 1, 4.398: 1, 32.3275: 1, 128.7775: 1, 141.621: 1, 19.036: 1, 50.1225: 1, 37.9995: 1, 124.1245: 1, 20.798: 1, 44.6525: 1, 46.2135: 1, 19.7665: 1, 32.674: 1, 211.67: 1, 13.955: 1, 22.3905: 1, 64.395: 1, 48.28: 1, 23.4415: 1, 33.6675: 1, 53.69: 1, 50.37: 1, 49.991: 1, 48.2275: 1, 25.3755: 1, 93.787: 1, 12.509: 1, 32.823: 1, 14.359: 1, 38.0205: 1, 53.0385: 1, 49.599: 1, 68.609: 1, 48.701: 1, 43.1925: 1, 60.2785: 1, 77.2285: 1, 136.2275: 1, 58.415: 1, 136.8775: 1, 30.2985: 1, 253.3825: 1, 34.1575: 1, 126.8725: 1, 101.789: 1, 35.496: 1, 144.7235: 1, 19.671: 1, 82.398: 1, 65.5055: 1, 81.8255: 1, 83.0575: 1, 13.21: 1, 23.602: 1, 25.8995: 1, 27.0265: 1, 48.113: 1, 23.5165: 1, 126.812: 1, 18.2885: 1, 13.2885: 1, 15.8625: 1, 26.7205: 1, 58.2135: 1, 16.202: 1, 96.481: 1, 5.0815: 1, 130.1605: 1, 91.555: 1, 60.723: 1, 9.4045: 1, 2.3635: 1, 15.515: 1, 52.184: 1, 30.339: 1, 2.4765: 1, 46.465: 1, 95.351: 1, 8.4115: 1, 124.684: 1, 93.576: 1, 6.221: 1, 52.3475: 1, 55.476: 1, 215.822: 1, 132.78: 1, 88.255: 1, 24.5135: 1, 18.535: 1, 92.915: 1, 54.3535: 1, 50.55: 1, 134.2665: 1, 42.574: 1, 30.484: 1, 126.323: 1, 108.1525: 1, 30.2215: 1, 178.8195: 1, 22.893: 1, 147.909: 1, 103.15: 1, 34.7105: 1, 25.0245: 1, 61.395: 1, 10.4415: 1, 18.1485: 1, 36.413: 1, 49.9735: 1, 95.48: 1, 56.8425: 1, 9.0075: 1, 10.8605: 1, 84.659: 1, 64.337: 1, 138.8155: 1, 31.2: 1, 20.904: 1, 28.485: 1, 34.3075: 1, 49.0175: 1, 53.6605: 1, 19.6825: 1, 94.4575: 1, 50.0455: 1, 47.29: 1, 133.1575: 1, 33.627: 1, 32.3385: 1, 12.32: 1, 101.1125: 1, 128.8255: 1, 23.173: 1, 46.31: 1, 21.6195: 1, 93.98: 1, 11.772: 1, 7.185: 1, 8.027: 1, 80.85: 1, 127.2825: 1, 181.4885: 1, 129.96: 1, 88.459: 1, 19.1195: 1, 6.64: 1, 96.9685: 1, 49.0235: 1, 129.45: 1, 19.5675: 1, 19.97: 1, 40.3385: 1, 95.6085: 1, 226.875: 1, 140.7375: 1, 25.608: 1, 157.14: 1, 49.08: 1, 21.576: 1, 37.62: 1, 137.19: 1, 19.985: 1, 128.8825: 1, 29.1695: 1, 20.02: 1, 43.6195: 1, 58.2: 1, 39.3535: 1, 36.807: 1, 150.93: 1, 10.5295: 1, 42.2535: 1, 7.2285: 1, 125.7375: 1, 101.886: 1, 55.25: 1, 225.7075: 1, 100.311: 1, 10.556: 1, 28.236: 1, 6.978: 1, 128.72: 1, 3.3635: 1, 176.0105: 1, 119.165: 1, 41.932: 1, 21.595: 1, 27.1055: 1, 123.402: 1, 12.3485: 1, 89.513: 1, 132.414: 1, 4.3075: 1, 132.9525: 1, 127.9425: 1, 79.223: 1, 21.0125: 1, 58.4765: 1, 29.97: 1, 33.05: 1, 16.301: 1, 48.0445: 1, 26.5585: 1, 55.112: 1, 48.3175: 1, 135.7045: 1, 132.0725: 1, 54.266: 1, 59.739: 1, 95.605: 1, 95.045: 1, 7.1325: 1, 106.2275: 1, 101.81: 1, 37.7155: 1, 135.756: 1, 42.5: 1, 65.18: 1, 56.485: 1, 16.681: 1, 49.8015: 1, 217.515: 1, 94.05: 1, 47.37: 1, 63.4745: 1, 42.605: 1, 180.95: 1, 47.7775: 1, 218.93: 1, 75.571: 1, 55.158: 1, 19.6075: 1, 12.8415: 1, 38.9125: 1, 50.939: 1, 12.2615: 1, 57.5175: 1, 254.046: 1, 21.3135: 1, 51.4775: 1, 138.459: 1, 264.4685: 1, 13.7405: 1, 28.8415: 1, 127.2: 1, 45.44: 1, 60.8935: 1, 5.2795: 1, 52.96: 1, 129.352: 1, 52.9385: 1, 45.6775: 1, 62.653: 1, 362.5595: 1, 12.075: 1, 52.7325: 1, 12.5965: 1, 55.3935: 1, 5.338: 1, 118.5695: 1, 23.667: 1, 27.755: 1, 104.415: 1, 152.875: 1, 8.978: 1, 11.09: 1, 28.876: 1, 131.518: 1, 62.0435: 1, 64.8295: 1, 176.3845: 1, 22.2635: 1, 182.6675: 1, 181.0875: 1, 131.158: 1, 48.1875: 1, 12.26: 1, 125.8165: 1, 17.093: 1, 28.3615: 1, 49.0795: 1, 47.0735: 1, 17.5995: 1, 155.6275: 1, 17.922: 1, 6.8815: 1, 33.29: 1, 6.9865: 1, 6.4175: 1, 17.49: 1, 53.664: 1, 7.844: 1, 100.265: 1, 130.045: 1, 17.039: 1, 48.597: 1, 47.17: 1, 56.6375: 1, 10.2735: 1, 141.2475: 1, 65.29: 1, 64.429: 1, 50.695: 1, 15.023: 1, 131.8425: 1, 127.13: 1, 11.768: 1, 39.943: 1, 157.968: 1, 60.6415: 1, 5.236: 1, 29.4295: 1, 67.279: 1, 225.7675: 1, 129.7525: 1, 53.08: 1, 5.5475: 1, 142.155: 1, 24.5485: 1, 7.4375: 1, 34.548: 1, 54.2575: 1, 35.0635: 1, 70.7345: 1, 60.653: 1, 5.451: 1, 3.314: 1, 3.9825: 1, 52.4595: 1, 25.535: 1, 53.64: 1, 13.6505: 1, 53.9195: 1, 165.9: 1, 211.479: 1, 172.4: 1, 18.3975: 1, 50.685: 1, 192.155: 1, 170.7625: 1, 56.624: 1, 14.8385: 1, 39.897: 1, 104.9925: 1, 142.9405: 1, 126.5575: 1, 48.005: 1, 31.7975: 1, 38.7425: 1, 52.22: 1, 95.0: 1, 69.122: 1, 50.974: 1, 34.414: 1, 49.0865: 1, 35.7365: 1, 152.6195: 1, 317.3975: 1, 32.2855: 1, 50.881: 1, 47.92: 1, 38.872: 1, 51.292: 1, 76.1625: 1, 140.818: 1, 102.21: 1, 51.911: 1, 61.61: 1, 12.008: 1, 155.0525: 1, 47.335: 1, 95.449: 1, 161.6955: 1, 39.374: 1, 90.5725: 1, 52.88: 1, 83.545: 1, 4.651: 1, 143.6325: 1, 155.104: 1, 132.6385: 1, 54.5645: 1, 133.8695: 1, 24.179: 1, 47.3525: 1, 56.1525: 1, 161.803: 1, 42.403: 1, 8.4235: 1, 45.0725: 1, 63.58: 1, 100.71: 1, 5.5: 1, 133.943: 1, 33.387: 1, 41.7415: 1, 55.305: 1, 34.2205: 1, 8.78: 1, 6.694: 1, 111.197: 1, 23.1895: 1, 123.5725: 1, 19.772: 1, 30.8655: 1, 50.124: 1, 210.9175: 1, 88.016: 1, 17.062: 1, 64.875: 1, 56.5: 1, 44.39: 1, 66.53: 1, 4.2885: 1, 23.754: 1, 93.0055: 1, 47.055: 1, 92.163: 1, 58.4675: 1, 6.149: 1, 27.2445: 1, 40.078: 1, 147.861: 1, 17.709: 1, 66.325: 1, 57.51: 1, 152.5725: 1, 134.67: 1, 55.3805: 1, 132.0375: 1, 98.5235: 1, 32.391: 1, 6.35: 1, 63.328: 1, 61.185: 1, 26.5145: 1, 19.757: 1, 38.944: 1, 47.9135: 1, 8.92: 1, 29.107: 1, 27.6065: 1, 50.043: 1, 21.3395: 1, 58.132: 1, 22.0625: 1, 31.583: 1, 13.8865: 1, 9.4895: 1, 222.4145: 1, 64.5005: 1, 249.9785: 1, 87.8475: 1, 150.2505: 1, 149.27: 1, 43.0695: 1, 17.2385: 1, 10.3075: 1, 126.2825: 1, 22.869: 1, 180.17: 1, 8.8035: 1, 258.27: 1, 138.9225: 1, 37.987: 1, 154.891: 1, 41.0555: 1, 95.6115: 1, 17.1455: 1, 19.983: 1, 45.26: 1, 51.995: 1, 14.7165: 1, 51.4155: 1, 22.1605: 1, 88.8015: 1, 172.5925: 1, 48.335: 1, 127.925: 1, 55.673: 1, 216.1475: 1, 80.6775: 1, 45.307: 1, 26.713: 1, 40.239: 1, 34.617: 1, 49.0035: 1, 41.7665: 1, 170.035: 1, 30.5475: 1, 210.57: 1, 54.8285: 1, 18.781: 1, 51.3955: 1, 45.057: 1, 134.6175: 1, 28.63: 1, 43.3825: 1, 42.4225: 1, 47.1315: 1, 37.1665: 1, 53.045: 1, 72.735: 1, 27.017: 1, 48.163: 1, 48.5745: 1, 138.4525: 1, 80.65: 1, 45.455: 1, 47.2275: 1, 145.9125: 1, 63.648: 1, 128.8625: 1, 15.1795: 1, 13.886: 1, 3.356: 1, 107.7515: 1, 126.674: 1, 73.4245: 1, 242.36: 1, 17.59: 1, 41.517: 1, 146.955: 1, 6.634: 1, 22.022: 1, 41.2565: 1, 28.933: 1, 110.8845: 1, 170.411: 1, 99.8415: 1, 141.76: 1, 69.9025: 1, 49.985: 1, 45.965: 1, 90.0625: 1, 77.7485: 1, 54.702: 1, 20.008: 1, 29.1615: 1, 131.258: 1, 60.956: 1, 130.6285: 1, 39.8355: 1, 126.1875: 1, 47.965: 1, 78.7355: 1, 29.9035: 1, 6.85: 1, 26.166: 1, 40.648: 1, 115.124: 1, 52.626: 1, 28.233: 1, 127.836: 1, 13.92: 1, 18.6875: 1, 37.672: 1, 26.038: 1, 31.175: 1, 91.2745: 1, 220.342: 1, 11.306: 1, 23.9565: 1, 18.7175: 1, 47.8015: 1, 15.5: 1, 52.885: 1, 130.245: 1, 85.896: 1, 19.586: 1, 16.973: 1, 45.3225: 1, 5.3265: 1, 100.734: 1, 10.867: 1, 14.986: 1, 131.957: 1, 141.065: 1, 19.294: 1, 24.796: 1, 7.987: 1, 195.775: 1, 36.198: 1, 132.7825: 1, 89.8775: 1, 131.2325: 1, 46.8015: 1, 87.7375: 1, 10.6565: 1, 128.9835: 1, 20.124: 1, 172.6785: 1, 34.4535: 1, 6.1475: 1, 133.115: 1, 17.0675: 1, 21.302: 1, 2.32: 1, 147.865: 1, 52.3055: 1, 92.3975: 1, 38.5535: 1, 23.8575: 1, 177.6405: 1, 88.385: 1, 38.037: 1, 84.595: 1, 158.2905: 1, 13.1065: 1, 64.9605: 1, 49.38: 1, 54.8335: 1, 102.4215: 1, 19.0765: 1, 172.9845: 1, 21.0495: 1, 43.313: 1, 54.1165: 1, 272.0925: 1, 15.1225: 1, 53.434: 1, 91.3305: 1, 13.6655: 1, 30.459: 1, 96.1875: 1, 80.34: 1, 71.34: 1, 156.7115: 1, 88.181: 1, 57.9695: 1, 16.2485: 1, 162.6825: 1, 59.685: 1, 140.535: 1, 55.615: 1, 52.2655: 1, 51.42: 1, 105.7055: 1, 114.504: 1, 15.21: 1, 39.7225: 1, 26.647: 1, 179.392: 1, 14.796: 1, 67.569: 1, 153.375: 1, 46.455: 1, 10.664: 1, 53.055: 1, 89.81: 1, 111.146: 1, 131.749: 1, 26.1565: 1, 69.149: 1, 20.7505: 1, 39.3395: 1, 85.7505: 1, 30.405: 1, 35.5805: 1, 51.7275: 1, 91.7495: 1, 48.17: 1, 108.721: 1, 48.1425: 1, 16.327: 1, 77.392: 1, 20.6865: 1, 5.347: 1, 9.6375: 1, 30.2285: 1, 38.2825: 1, 54.08: 1, 27.308: 1, 95.921: 1, 21.122: 1, 16.685: 1, 11.21: 1, 45.2995: 1, 60.1375: 1, 186.215: 1, 44.3225: 1, 376.2925: 1, 50.046: 1, 124.2875: 1, 22.983: 1, 171.53: 1, 30.114: 1, 17.205: 1, 13.7695: 1, 57.1965: 1, 5.085: 1, 58.9775: 1, 138.3485: 1, 80.1435: 1, 35.042: 1, 5.85: 1, 56.6725: 1, 119.405: 1, 56.696: 1, 56.81: 1, 72.4405: 1, 44.4465: 1})\n",
            "Counter({2.5: 6, 24.932: 3, 48.109: 3, 53.08: 2, 22.6425: 2, 48.0625: 2, 47.7325: 2, 3.5: 2, 48.16: 2, 9.64: 2, 47.9825: 2, 32.902: 2, 49.312: 2, 0.0: 2, 29.3875: 1, 50.84: 1, 147.7315: 1, 65.1165: 1, 111.8055: 1, 21.5635: 1, 102.735: 1, 47.956: 1, 0.825: 1, 33.983: 1, 32.3795: 1, 47.645: 1, 45.8135: 1, 23.73: 1, 46.83: 1, 206.795: 1, 11.9865: 1, 12.089: 1, 56.77: 1, 10.657: 1, 69.831: 1, 17.6775: 1, 68.833: 1, 24.1845: 1, 18.962: 1, 120.805: 1, 29.1325: 1, 21.469: 1, 46.5425: 1, 49.945: 1, 140.655: 1, 47.8425: 1, 11.9595: 1, 38.4305: 1, 28.569: 1, 9.5525: 1, 72.52: 1, 33.6315: 1, 26.08: 1, 128.9925: 1, 143.138: 1, 147.029: 1, 31.543: 1, 61.345: 1, 80.5565: 1, 49.136: 1, 4.4125: 1, 28.7045: 1, 56.3635: 1, 44.2725: 1, 17.68: 1, 35.495: 1, 88.1725: 1, 37.0835: 1, 54.5645: 1, 11.7215: 1, 17.3055: 1, 141.341: 1, 25.797: 1, 47.5075: 1, 146.624: 1, 132.0025: 1, 50.0155: 1, 59.36: 1, 87.34: 1, 24.814: 1, 24.63: 1, 50.716: 1, 128.8: 1, 13.195: 1, 88.3925: 1, 51.0215: 1, 7.3895: 1, 47.838: 1, 48.56: 1, 28.0755: 1, 156.9325: 1, 95.83: 1, 36.8075: 1, 244.0635: 1, 7.47: 1, 87.313: 1, 2.188: 1, 47.37: 1, 43.6885: 1, 45.8975: 1, 35.631: 1, 181.5775: 1, 17.2595: 1, 23.881: 1, 129.727: 1, 48.913: 1, 47.298: 1, 22.937: 1, 52.88: 1, 48.475: 1, 11.4185: 1, 269.8375: 1, 121.395: 1, 58.3325: 1, 96.367: 1, 56.73: 1, 146.9: 1, 27.181: 1, 157.09: 1, 79.8975: 1, 52.915: 1, 16.7335: 1, 52.2275: 1, 31.7375: 1, 7.985: 1, 46.333: 1, 45.2775: 1, 160.2655: 1, 29.694: 1, 34.8835: 1, 47.2065: 1, 77.88: 1, 83.409: 1, 15.2725: 1, 54.09: 1, 167.9855: 1, 21.9595: 1, 26.048: 1, 11.7755: 1, 54.49: 1, 47.7875: 1, 32.3015: 1, 25.667: 1, 147.3705: 1, 14.8155: 1, 93.232: 1, 28.061: 1, 0.75: 1, 276.5925: 1, 33.9915: 1, 49.39: 1, 141.087: 1, 109.81: 1, 8.241: 1, 20.5665: 1, 155.42: 1, 9.61: 1, 65.6815: 1, 18.935: 1, 48.011: 1, 30.7465: 1, 50.1205: 1, 311.6595: 1, 7.174: 1, 18.4345: 1, 31.902: 1, 166.6675: 1, 22.37: 1, 127.7825: 1, 32.447: 1, 97.794: 1, 53.045: 1, 129.806: 1, 19.7915: 1, 176.2855: 1, 46.4575: 1, 41.757: 1, 82.187: 1, 66.2945: 1, 32.538: 1, 100.1525: 1, 130.9075: 1, 190.3795: 1, 85.0595: 1, 64.953: 1, 62.373: 1, 4.2705: 1, 46.42: 1, 46.78: 1, 7.5: 1, 13.92: 1, 57.3475: 1, 26.789: 1, 26.5905: 1, 48.0495: 1, 25.4185: 1, 20.3435: 1, 9.1345: 1, 47.7685: 1, 16.7135: 1, 56.821: 1, 137.86: 1, 95.7475: 1, 49.289: 1, 139.001: 1, 36.7035: 1, 8.8635: 1, 9.175: 1, 221.76: 1, 72.6275: 1, 44.9005: 1, 20.277: 1, 51.7855: 1, 122.0095: 1, 75.467: 1, 123.4295: 1, 41.997: 1, 10.071: 1, 6.8815: 1, 76.0685: 1, 26.816: 1, 21.343: 1, 27.488: 1, 2.5575: 1, 11.64: 1, 140.4075: 1, 4.3335: 1, 137.7475: 1, 56.1: 1, 28.624: 1, 59.165: 1, 50.084: 1, 4.3185: 1, 11.5685: 1, 127.316: 1, 36.2825: 1, 112.9825: 1, 143.4085: 1, 24.319: 1, 30.5845: 1, 10.8605: 1, 49.295: 1, 157.8875: 1, 43.1875: 1, 82.7245: 1, 48.133: 1, 50.1775: 1, 205.3925: 1, 84.771: 1, 50.3675: 1, 41.3205: 1, 94.6375: 1, 45.455: 1, 14.78: 1, 129.243: 1, 335.9425: 1, 24.8955: 1, 130.0655: 1, 25.9925: 1, 45.553: 1, 54.0955: 1, 76.3475: 1, 51.181: 1, 229.431: 1, 128.935: 1, 51.61: 1, 128.8625: 1, 178.528: 1, 131.7525: 1, 107.46: 1, 46.176: 1, 20.8365: 1, 71.781: 1, 129.17: 1, 10.7705: 1, 48.0465: 1, 175.1225: 1, 53.6375: 1, 5.1895: 1, 204.3845: 1, 132.558: 1, 6.9265: 1, 11.8195: 1, 5.5335: 1, 17.039: 1, 16.073: 1, 20.042: 1, 249.2705: 1, 30.0205: 1, 47.2515: 1, 26.224: 1, 58.1835: 1, 96.438: 1, 28.287: 1, 141.6175: 1, 49.0035: 1, 157.1285: 1, 45.4425: 1, 47.14: 1, 28.316: 1, 47.0425: 1, 23.005: 1, 25.1415: 1, 50.815: 1, 75.4425: 1, 17.6985: 1, 18.5925: 1, 49.2945: 1, 159.2: 1, 133.4435: 1, 98.1075: 1, 21.173: 1, 28.741: 1, 133.21: 1, 37.646: 1, 65.634: 1, 5.1235: 1, 253.45: 1, 14.9825: 1, 208.454: 1, 47.215: 1, 47.1875: 1, 8.5175: 1, 49.1875: 1, 21.6065: 1, 147.1975: 1, 4.507: 1, 115.287: 1, 180.66: 1, 47.57: 1, 16.2685: 1, 106.286: 1, 137.401: 1, 32.073: 1, 56.2975: 1, 146.871: 1, 56.59: 1, 22.89: 1, 141.57: 1, 44.627: 1, 8.005: 1, 48.1435: 1, 39.514: 1, 129.6525: 1, 36.3905: 1, 109.276: 1, 2.62: 1, 81.3835: 1, 56.06: 1, 24.865: 1, 78.98: 1, 51.669: 1, 29.648: 1, 21.177: 1, 40.241: 1, 34.8365: 1, 129.3375: 1, 100.8975: 1, 133.1425: 1, 134.0375: 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKrf7_a23YOw"
      },
      "source": [
        "Creating the Embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOQDMEcHm49c"
      },
      "source": [
        "import os\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join('','tweets_embedding.txt'),encoding=\"utf-8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:])\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()    "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtBpNUfhpz3j"
      },
      "source": [
        "Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxvwpIMPtGqi"
      },
      "source": [
        "num_words = len(word_index) + 1\n",
        "embedding_matrix = np.zeros((num_words,EMBEDDING_DIM))\n",
        "\n",
        "for word,i in word_index.items():\n",
        "    if i > num_words:\n",
        "        continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkjovhgDt7At",
        "outputId": "3e84a0d5-1b42-4e3a-ec8d-4407ce6a58b1"
      },
      "source": [
        "print(num_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRxz_0qbHtGm"
      },
      "source": [
        "def get_class_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_words ,EMBEDDING_DIM))\n",
        "    model.add(LSTM(1, activation=\"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy',optimizer='adam' , metrics=['accuracy'])\n",
        "\n",
        "model=get_model2()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mBQZUb9eB6e"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbUQsHcyEuic"
      },
      "source": [
        "def get_reg_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(Embedding(num_words ,EMBEDDING_DIM))\n",
        "    model.add(LSTM(1, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "model=get_reg_model()\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i69J5WF4_DO"
      },
      "source": [
        "Model Training Finally...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QavzjDRzKNgc",
        "outputId": "501c6a1e-68b6-4821-db56-2cc534aba0b0"
      },
      "source": [
        "model.fit(x_train_pad, y_train, batch_size=10, epochs=20,validation_data=(x_test_pad, y_test))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "153/153 [==============================] - 4s 17ms/step - loss: 6979.5439 - mae: 62.8913 - val_loss: 7165.8052 - val_mae: 62.5990\n",
            "Epoch 2/20\n",
            "153/153 [==============================] - 2s 15ms/step - loss: 6926.0566 - mae: 62.4949 - val_loss: 7119.3711 - val_mae: 62.2298\n",
            "Epoch 3/20\n",
            "153/153 [==============================] - 2s 15ms/step - loss: 6882.2837 - mae: 62.1188 - val_loss: 7076.5664 - val_mae: 61.8910\n",
            "Epoch 4/20\n",
            "153/153 [==============================] - 2s 15ms/step - loss: 6844.3696 - mae: 61.8323 - val_loss: 7037.7314 - val_mae: 61.5828\n",
            "Epoch 5/20\n",
            "153/153 [==============================] - 2s 15ms/step - loss: 6797.7578 - mae: 61.4865 - val_loss: 6999.3428 - val_mae: 61.2778\n",
            "Epoch 6/20\n",
            "153/153 [==============================] - 2s 15ms/step - loss: 6769.9297 - mae: 61.1901 - val_loss: 6963.9761 - val_mae: 60.9946\n",
            "Epoch 7/20\n",
            "153/153 [==============================] - 2s 16ms/step - loss: 6725.8647 - mae: 60.9000 - val_loss: 6928.6060 - val_mae: 60.7115\n",
            "Epoch 8/20\n",
            "153/153 [==============================] - 2s 16ms/step - loss: 6699.2134 - mae: 60.6171 - val_loss: 6894.6060 - val_mae: 60.4464\n",
            "Epoch 9/20\n",
            "153/153 [==============================] - 2s 15ms/step - loss: 6646.4028 - mae: 60.3108 - val_loss: 6859.6172 - val_mae: 60.1772\n",
            "Epoch 10/20\n",
            "153/153 [==============================] - 2s 16ms/step - loss: 6598.4067 - mae: 59.9144 - val_loss: 6824.7295 - val_mae: 59.9062\n",
            "Epoch 11/20\n",
            "153/153 [==============================] - 2s 15ms/step - loss: 6577.3906 - mae: 59.7457 - val_loss: 6791.3237 - val_mae: 59.6471\n",
            "Epoch 12/20\n",
            "153/153 [==============================] - 2s 15ms/step - loss: 6546.0034 - mae: 59.5103 - val_loss: 6758.3813 - val_mae: 59.3929\n",
            "Epoch 13/20\n",
            "153/153 [==============================] - 2s 15ms/step - loss: 6515.9077 - mae: 59.1958 - val_loss: 6726.1157 - val_mae: 59.1418\n",
            "Epoch 14/20\n",
            "153/153 [==============================] - 2s 16ms/step - loss: 6481.7046 - mae: 58.9106 - val_loss: 6693.8838 - val_mae: 58.8915\n",
            "Epoch 15/20\n",
            "153/153 [==============================] - 2s 16ms/step - loss: 6460.7480 - mae: 58.8010 - val_loss: 6662.2886 - val_mae: 58.6495\n",
            "Epoch 16/20\n",
            "153/153 [==============================] - 2s 16ms/step - loss: 6437.9497 - mae: 58.5450 - val_loss: 6631.8218 - val_mae: 58.4160\n",
            "Epoch 17/20\n",
            "153/153 [==============================] - 2s 16ms/step - loss: 6393.5854 - mae: 58.2694 - val_loss: 6600.6831 - val_mae: 58.1768\n",
            "Epoch 18/20\n",
            "153/153 [==============================] - 2s 15ms/step - loss: 6358.1387 - mae: 58.0699 - val_loss: 6569.6191 - val_mae: 57.9370\n",
            "Epoch 19/20\n",
            "153/153 [==============================] - 2s 15ms/step - loss: 6319.8970 - mae: 57.7737 - val_loss: 6539.4639 - val_mae: 57.7032\n",
            "Epoch 20/20\n",
            "153/153 [==============================] - 2s 16ms/step - loss: 6296.0825 - mae: 57.4715 - val_loss: 6509.3164 - val_mae: 57.4705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1fe2fbaa10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RrkQV0aergH"
      },
      "source": [
        "model.save('MH2_reg_model.h5')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygw08JqLkU7b"
      },
      "source": [
        "reconstructed_model = keras.models.load_model('/content/MH2_reg_model.h5')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4CLQO0ze7zd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b7a3226-8e53-400a-f118-789d327f213d"
      },
      "source": [
        "model=load_model('/content/MH2_reg_model.h5')\n",
        "with open('/content/tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "\n",
        "data = clean_tweet('scary days are the worst')\n",
        "seq=tokenizer.texts_to_sequences(data)\n",
        "data = pad_sequences(seq,maxlen=200)\n",
        "prediction=np.argmax(model.predict(data),axis=1)\n",
        "output=model.predict(data)\n",
        "output"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.142847 ],\n",
              "       [6.1428204],\n",
              "       [6.1429157],\n",
              "       [6.0990944],\n",
              "       [6.1425996],\n",
              "       [6.142913 ],\n",
              "       [6.1428604],\n",
              "       [6.1429157],\n",
              "       [6.1425996],\n",
              "       [6.142913 ],\n",
              "       [6.1429157],\n",
              "       [6.0990944],\n",
              "       [6.142397 ],\n",
              "       [6.142913 ],\n",
              "       [6.1428967],\n",
              "       [6.1427107],\n",
              "       [6.142397 ],\n",
              "       [6.142913 ],\n",
              "       [6.1428165],\n",
              "       [6.1428323],\n",
              "       [6.0990944],\n",
              "       [6.142847 ],\n",
              "       [6.1428967]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LMVt1XPM7uX"
      },
      "source": [
        "data=pd.read_csv('/content/Mental_health.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "jjnXJ1l9NUsP",
        "outputId": "5275418e-8f44-44e8-919f-8edca42afe2b"
      },
      "source": [
        "data['labels'].value_counts().plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3e6f9c1c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGUcoRa3iJ7v",
        "outputId": "1a71b214-f761-47dc-fb5d-e7de730cbcbc"
      },
      "source": [
        "\n",
        "prediction=model.predict(data)\n",
        "prediction_class = prediction.argmax(axis=-1)[0][0]\n",
        "print(prediction_class)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-UNdK-yCTLB"
      },
      "source": [
        "# Streamlit code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1Rl66cqiRQcl",
        "outputId": "5cb0a5c6-547c-4cfd-bdd7-6c7c6389f3af"
      },
      "source": [
        "!pip install streamlit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/11/57097e14f72a2d1b2a1bbe86c2a8bc375661bfd5c30b5e8cee7c2fad9a44/streamlit-0.82.0-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     || 8.2MB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<8.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n",
            "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.12.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit) (20.9)\n",
            "Collecting watchdog; platform_system != \"Darwin\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/5b/36b3b11e557830de6fc1dc06e9aa3ee274119b8cea9cc98175dbbf72cf87/watchdog-2.1.2-py3-none-manylinux2014_x86_64.whl (74kB)\n",
            "\u001b[K     || 81kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.2)\n",
            "Collecting blinker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/51/e2a9f3b757eb802f61dc1f2b09c8c99f6eb01cf06416c0671253536517b6/blinker-1.4.tar.gz (111kB)\n",
            "\u001b[K     || 112kB 46.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.8.1)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.1.0)\n",
            "Requirement already satisfied: pyarrow; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.0.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.10.2)\n",
            "Collecting base58\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/a1/d9f565e9910c09fd325dc638765e8843a19fa696275c16cc08cf3b0a3c25/base58-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.1.5)\n",
            "Collecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/da/6f6224fdfc47dab57881fe20c0d1bc3122be290198ba0bf26a953a045d92/GitPython-3.1.17-py3-none-any.whl (166kB)\n",
            "\u001b[K     || 174kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.19.5)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/bc/f0e44828e4290367c869591d50d3671a4d0ee94926da6cb734b7b200308c/pydeck-0.6.2-py2.py3-none-any.whl (4.2MB)\n",
            "\u001b[K     || 4.2MB 34.1MB/s \n",
            "\u001b[?25hCollecting validators\n",
            "  Downloading https://files.pythonhosted.org/packages/db/2f/7fed3ee94ad665ad2c1de87f858f10a7785251ff75b4fd47987888d07ef1/validators-0.18.2-py3-none-any.whl\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tzlocal->streamlit) (2018.9)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (57.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit) (2.4.7)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from gitpython->streamlit) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     || 71kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.6.3)\n",
            "Collecting ipykernel>=5.1.2; python_version >= \"3.4\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/6d/6c8fe4b658f77947d4244ce81f60230c4c8d1dc1a21ae83e63b269339178/ipykernel-5.5.5-py3-none-any.whl (120kB)\n",
            "\u001b[K     || 122kB 41.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->streamlit) (4.4.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.3)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.5.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (5.3.5)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.7.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.18)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (22.0.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.10.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.3.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
            "Building wheels for collected packages: blinker\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-cp37-none-any.whl size=13476 sha256=bb79f392b6daa6f99c3850cdce7d385a35cce5488805dcccae40c84307375e91\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a0/00/8690a57883956a301d91cf4ec999cc0b258b01e3f548f86e89\n",
            "Successfully built blinker\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.5.5 which is incompatible.\u001b[0m\n",
            "Installing collected packages: watchdog, blinker, base58, smmap, gitdb, gitpython, ipykernel, pydeck, validators, streamlit\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "Successfully installed base58-2.1.0 blinker-1.4 gitdb-4.0.7 gitpython-3.1.17 ipykernel-5.5.5 pydeck-0.6.2 smmap-4.0.0 streamlit-0.82.0 validators-0.18.2 watchdog-2.1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipykernel"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_1Tz-ZLjwAh"
      },
      "source": [
        "from keras import backend as K\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from nltk.tokenize import word_tokenize\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "wordnet = WordNetLemmatizer()\n",
        "regex = re.compile('[%s]' % re.escape(string.punctuation))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKqPfmfQAWyE"
      },
      "source": [
        "MODEL_PATH = '/content/MH/saved_model.pb'\n",
        "MAX_NB_WORDS = 100000 # max no. of words for tokenizer\n",
        "MAX_SEQUENCE_LENGTH = 200 # max length of each entry (sentence), including padding\n",
        "VALIDATION_SPLIT = 0.2 # data for validation (not used in training)\n",
        "EMBEDDING_DIM = 100\n",
        "tokenizer_file = 'tokenizer.pickle'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plfKV0oIB_8b"
      },
      "source": [
        "with open(tokenizer_file, 'rb') as handle:\n",
        "   tokenizer = pickle.load(handle)\n",
        "@st.cache(allow_output_mutation=True)\n",
        "def Load_model():\n",
        "   model = reconstructed_model\n",
        "   model.summary() # included to make it visible when model is reloaded\n",
        "   session = K.get_session()\n",
        "   return model, session\n",
        "\n",
        "   Load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JV1FqeRTCkl"
      },
      "source": [
        "#@st.cache\n",
        "#def load_my_model():\n",
        "model = reconstructed_model\n",
        " \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    st.title('A simple streamlit mental health app')\n",
        "    st.write('Want to know if your tweets contain some depressive characteristics')\n",
        "    st.subheader('Key in or paste one of your tweets') \n",
        "    tweet=st.text_area('') \n",
        "    prediction_btn = st.button('predict')\n",
        "    if prediction_btn:\n",
        "        clean_text = []\n",
        "        #K.set_session(session)\n",
        "        i = clean_tweet(tweet)\n",
        "        clean_text.append(i)\n",
        "        sequences = tokenizer.texts_to_sequences(clean_text)\n",
        "        data = pad_sequences(sequences, maxlen = max_length)\n",
        "        prediction = model.predict(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsXUSSw_CG2y"
      },
      "source": [
        "if prediction_btn:\n",
        "   clean_text = []\n",
        "   K.set_session(session)\n",
        "   i = clean_tweet(tweet)\n",
        "   clean_text.append(i)\n",
        "   sequences = tokenizer.texts_to_sequences(clean_text)\n",
        "   data = pad_sequences(sequences, maxlen = max_length)\n",
        "   prediction = model.predict(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_KjZmvCOLYp"
      },
      "source": [
        "prediction_class = prediction.argmax(axis=-1)[0]\n",
        "\n",
        "\n",
        "st.header(\"Prediction using LSTM model\")\n",
        "if prediction_class == 0:\n",
        "    st.success()\n",
        "if prediction_class == 1:\n",
        "    st.success()\n",
        "if prediction_class == 2:\n",
        "    st.success()\n",
        "if prediction_class == 3:\n",
        "    st.success()\n",
        "if prediction_class == 4:\n",
        "    st.success()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBA-YKHqQAu3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrPDCr5NJVEF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "outputId": "b4cfd8f7-3557-4521-9bed-45bdf0a2d5e5"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    st.title('A simple streamlit mental health app')\n",
        "    st.write('Want to know if your tweets contain some depressive characteristics')\n",
        "    st.subheader('Key in or paste one of your tweets') \n",
        "    tweet=st.text_area('') \n",
        "    prediction_btn = st.button('predict')\n",
        "    model= Load_model()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InternalHashError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/streamlit/hashing.py\u001b[0m in \u001b[0;36mto_bytes\u001b[0;34m(self, obj, context)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;31m# Hash the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"%s:%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/streamlit/hashing.py\u001b[0m in \u001b[0;36m_to_bytes\u001b[0;34m(self, obj, context)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_should_be_hashed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__code__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mco_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/streamlit/hashing.py\u001b[0m in \u001b[0;36m_file_should_be_hashed\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    386\u001b[0m         return file_util.file_is_in_folder_glob(\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_main_script_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         ) or file_util.file_in_pythonpath(filepath)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/streamlit/hashing.py\u001b[0m in \u001b[0;36m_get_main_script_directory\u001b[0;34m()\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;31m# script path in ScriptRunner.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0mmain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__main__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module '__main__' has no attribute '__file__'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInternalHashError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-54d7ba448079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtweet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_area\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprediction_btn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbutton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mLoad_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/streamlit/caching.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshow_spinner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspinner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mget_or_create_cached_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_or_create_cached_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/streamlit/caching.py\u001b[0m in \u001b[0;36mget_or_create_cached_value\u001b[0;34m()\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0;31m# If we generated the key earlier we would only hash those\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                 \u001b[0;31m# globals by name, and miss changes in their code or value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m                 \u001b[0mcache_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_hash_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_funcs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0;31m# First, get the cache that's attached to this function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/streamlit/caching.py\u001b[0m in \u001b[0;36m_hash_func\u001b[0;34m(func, hash_funcs)\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0mhash_funcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhash_funcs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0mhash_reason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHashReason\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCACHING_FUNC_BODY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mhash_source\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     )\n\u001b[1;32m    631\u001b[0m     \u001b[0mcache_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_hasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/streamlit/hashing.py\u001b[0m in \u001b[0;36mupdate_hash\u001b[0;34m(val, hasher, hash_reason, hash_source, context, hash_funcs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CodeHasher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash_funcs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/streamlit/hashing.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, hasher, obj, context)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;34m\"\"\"Update the provided hasher with the hash of an object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0mhasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/streamlit/hashing.py\u001b[0m in \u001b[0;36mto_bytes\u001b[0;34m(self, obj, context)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInternalHashError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/streamlit/hashing.py\u001b[0m in \u001b[0;36mto_bytes\u001b[0;34m(self, obj, context)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;31m# Hash the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"%s:%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;31m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/streamlit/hashing.py\u001b[0m in \u001b[0;36m_to_bytes\u001b[0;34m(self, obj, context)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"md5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_should_be_hashed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__code__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mco_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__defaults__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/streamlit/hashing.py\u001b[0m in \u001b[0;36m_file_should_be_hashed\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         return file_util.file_is_in_folder_glob(\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_main_script_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         ) or file_util.file_in_pythonpath(filepath)\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/streamlit/hashing.py\u001b[0m in \u001b[0;36m_get_main_script_directory\u001b[0;34m()\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# This works because we set __main__.__file__ to the report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;31m# script path in ScriptRunner.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0mmain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__main__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalHashError\u001b[0m: module '__main__' has no attribute '__file__'\n\nWhile caching the body of `Load_model()`, Streamlit encountered an\nobject of type `builtins.function`, which it does not know how to hash.\n\n**In this specific case, it's very likely you found a Streamlit bug so please\n[file a bug report here.]\n(https://github.com/streamlit/streamlit/issues/new/choose)**\n\nIn the meantime, you can try bypassing this error by registering a custom\nhash function via the `hash_funcs` keyword in @st.cache(). For example:\n\n```\n@st.cache(hash_funcs={builtins.function: my_hash_func})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type `builtins.function` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type builtins.function: <function Load_model at 0x7f6cfcfd6830>\n```\n\nPlease see the `hash_funcs` [documentation]\n(https://docs.streamlit.io/en/stable/caching.html#the-hash-funcs-parameter)\nfor more details.\n            "
          ]
        }
      ]
    }
  ]
}